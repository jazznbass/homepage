{
  "hash": "c705263241f232a2bd237c703e5e16e0",
  "result": {
    "markdown": "---\ntitle: Multivariate multilevel analyses\nsubtitle: A hands on primer in R\nauthor: Jürgen Wilbert\ndate: 2021/03/17\noutput:\n  html_document:\n    toc: yes\n    toc_depth: 2\n    toc_float: yes\n    df_print: default\n    theme: journal\n  pdf_document: \n    toc: yes\n    toc_depth: 2\n    latex_engine: xelatex\nkeywords: \n  - Statistics\n  - R\n  - Multilevel\n  - Bayesian\n  - nlme\n  - MCMCglmm\nabstract: A short description how to do Multivariate Multilevel Analyses in R with the `nlme` and\n  `MCMCglmm` packages\n---\n\n*Keywords:  Statistics, R, Multilevel, Bayesian, nlme, MCMCglmm *\n\n\n# Problem\n\nMost of our data have a multilevel structure. But \"standard\" Manova analyzes do not take a nested structure with various strata into account. What we need is a multivariate extension of the univariate multilevel regression approach.\n\nMultivariate multilevel analyses has various subtypes depending on the assumptions of the intercorrelations and variance of the dependent variables (dvs).\n\nIn this paper by Ben Bolker (<https://rpubs.com/bbolker/3336>), five subtypes are described. Interestingly, the case \\#1 assumes equal variance of all dvs and equal (positive ?) correlations among the dvs. In this case, is is very easy: A random slope model with the dvs turned into a new random slope categorical variable.\\\nWhen dvs have different variances, the models must be weighted by their variance and when the intercorrelation between the dvs varies, the intercorrelations of the residuals have to be fixed to take these variations into account.\n\nOne approach is a Bayesian analyses with a Markov-Chain Monte-Carlo method. There is a vignette of the MCMCglmm package that explains how to do these analyses more in detail ([\\<https://cran.r-project.org/web/packages/MCMCglmm/vignettes/CourseNotes.pdf\\>](https://cran.r-project.org/web/packages/MCMCglmm/vignettes/CourseNotes.pdf){.uri}). Note: This example is for repeated measures.\n\n# A frequentist approach\n\nSnijders and Bosker (2012) describe multivariate multilevel analyses and they provide an [R example](https://www.stats.ox.ac.uk/~snijders/ch16.r) on this webage <https://www.stats.ox.ac.uk/~snijders/mlbook.htm>.\n\n> Page 284 of Snijders and Bosker 2012: \"To represent the multivariate data in the multilevel approach, three nesting levels are used. The first level is that of the dependent variables indexed by ℎ=1,...,𝑚, the second level is that of the individuals 𝑖=1,...,𝑛𝑗, and the third level is that of the groups, 𝑗=1,...,𝑁. So each measurement of a dependent variable on some individual is represented by a separate line in the data matrix, containing the values 𝑖, 𝑗, 𝑗, 𝑌ℎ𝑖𝑗, 𝑥1𝑖𝑗, and those of the other explanatory variables. The multivariate model is formulated as hierarchical linear model using the same trick as in Section 15.1.3. Dummy variables 𝑑1,...,𝑑𝑚 are used to indicate the dependent variables, just as in formula (14.2). Dummy variable 𝑑ℎ is 1 or 0, depending on whether the data line refers to dependent variable 𝑌𝑗 or to one of the other dependent variables.\"\n\n## A computational example\n\nFirst we need an example dataset to work with. I want two criteria (av1 and av2) and one explanatory variable (dv1) nested within four groups\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1234)\nncases <- 800\nngroups <- 4\ndat <- list()\ndat$id <- 1:ncases\ndat$group <- rep_len(1:ngroups, ncases)\ndat$av1 <- rnorm(ncases, 50, 10)\ndat$av2 <- (dat$av1 + rnorm(ncases, 50, 10)) / 2\ndat$dv1 <- (dat$av1 + dat$av2 + rnorm(ncases, 50, 10)) /3\ndat$av1 <- dat$av1 + (dat$group / ngroups * 10)\ndat$av2 <- dat$av2 + (dat$group / ngroups * 10)\ndat$dv1 <- dat$dv1 + (dat$group / ngroups * 10)\ndat$dv1 <- scale(dat$dv1, scale = FALSE)\n#dat$id <- rep(1:ncases, ngroups)\n#dat$obs <- 1:(ncases*ngroups)\ndat <- as.data.frame(dat)\n\ndat2 <- dat %>%\n  pivot_longer(cols = c(\"av1\", \"av2\"), names_to = \"trait\") %>%\n  mutate(trait = as.factor(trait))\n```\n:::\n\n\n## Manova without nesting data structure\n\nThe simple Manova has some disadvantages here:\n\n-   No nested data structure\n\n-   Assumes all variances are equal (also: across all strata, which it does not take into account anyway).\n\n-   Assumes all intercorrelations of the variables are equal (again also across all strata)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel <- lm(cbind(av1+av2) ~ 1 + dv1, data = dat)\nsummary(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = cbind(av1 + av2) ~ 1 + dv1, data = dat)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-30.0270  -5.3806   0.1014   5.6296  24.7045 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 112.1179     0.3033  369.69   <2e-16 ***\ndv1           2.0226     0.0430   47.04   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.578 on 798 degrees of freedom\nMultiple R-squared:  0.735,\tAdjusted R-squared:  0.7346 \nF-statistic:  2213 on 1 and 798 DF,  p-value: < 2.2e-16\n```\n:::\n\n```{.r .cell-code}\ncar::Anova(model, type = \"III\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnova Table (Type III tests)\n\nResponse: cbind(av1 + av2)\n              Sum Sq  Df  F value    Pr(>F)    \n(Intercept) 10056336   1 136672.2 < 2.2e-16 ***\ndv1           162828   1   2212.9 < 2.2e-16 ***\nResiduals      58717 798                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\n## Multilevel regression approach\n\nThe following analyses follow the example of Snijders and Bosker (2012, Chapter 16).\n\nNote: Dropping the intercept will set the main effect predictors of the dummy variable to the mean of the first variable. Also, dropping the main effect of the variable for the interaction will have an analogues effect for the interactions: the interaction with the first variable is displayed (otherwise, the main effect would entail the interaction of the first - here dummy - category and the variable).\\\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_1 <- lme(value ~ 0 + trait + dv1:trait, random = ~ 0 + trait |group,\ndata = dat2)\nsummary(model_1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed-effects model fit by REML\n  Data: dat2 \n       AIC      BIC    logLik\n  9937.194 9980.196 -4960.597\n\nRandom effects:\n Formula: ~0 + trait | group\n Structure: General positive-definite, Log-Cholesky parametrization\n         StdDev    Corr  \ntraitav1 1.2311183 tratv1\ntraitav2 0.5143689 -0.816\nResidual 5.3422224       \n\nFixed effects:  value ~ 0 + trait + dv1:trait \n                Value Std.Error   DF   t-value p-value\ntraitav1     55.97952 0.6438845 1593  86.94032       0\ntraitav2     56.13836 0.3190894 1593 175.93303       0\ntraitav1:dv1  1.24563 0.0292196 1593  42.62999       0\ntraitav2:dv1  0.81402 0.0279074 1593  29.16883       0\n Correlation: \n             tratv1 tratv2 trt1:1\ntraitav2     -0.628              \ntraitav1:dv1  0.000  0.000       \ntraitav2:dv1  0.000  0.000 -0.038\n\nStandardized Within-Group Residuals:\n        Min          Q1         Med          Q3         Max \n-4.69589000 -0.66817031  0.02572767  0.63497999  3.13414812 \n\nNumber of Observations: 1600\nNumber of Groups: 4 \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#with weighted variances\nmodel_1b <- update(model_1,  weights=varIdent(form=~1|trait))\nsummary(model_1b)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed-effects model fit by REML\n  Data: dat2 \n       AIC      BIC    logLik\n  9870.822 9919.199 -4926.411\n\nRandom effects:\n Formula: ~0 + trait | group\n Structure: General positive-definite, Log-Cholesky parametrization\n         StdDev    Corr  \ntraitav1 1.2103832 tratv1\ntraitav2 0.5547227 -0.774\nResidual 6.0607475       \n\nVariance function:\n Structure: Different standard deviations per stratum\n Formula: ~1 | trait \n Parameter estimates:\n      av1       av2 \n1.0000000 0.7442685 \nFixed effects:  value ~ 0 + trait + dv1:trait \n                Value Std.Error   DF   t-value p-value\ntraitav1     55.97952 0.6420068 1593  87.19460       0\ntraitav2     56.13836 0.3199433 1593 175.46347       0\ntraitav1:dv1  1.24415 0.0329916 1593  37.71123       0\ntraitav2:dv1  0.81271 0.0239648 1593  33.91260       0\n Correlation: \n             tratv1 tratv2 trt1:1\ntraitav2     -0.632              \ntraitav1:dv1  0.000  0.000       \ntraitav2:dv1  0.000  0.000 -0.037\n\nStandardized Within-Group Residuals:\n        Min          Q1         Med          Q3         Max \n-4.13902014 -0.69797783  0.02637369  0.64981098  2.76937510 \n\nNumber of Observations: 1600\nNumber of Groups: 4 \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#correlation between dvs\nmodel_1c <- update(model_1b, corr = corSymm(form = ~ as.numeric(trait)|group/id))\n\nsummary(model_1c)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed-effects model fit by REML\n  Data: dat2 \n       AIC      BIC    logLik\n  9800.954 9854.707 -4890.477\n\nRandom effects:\n Formula: ~0 + trait | group\n Structure: General positive-definite, Log-Cholesky parametrization\n         StdDev    Corr  \ntraitav1 1.2152290 tratv1\ntraitav2 0.5592672 -0.832\nResidual 6.0605912       \n\nCorrelation Structure: General\n Formula: ~as.numeric(trait) | group/id \n Parameter estimate(s):\n Correlation: \n  1    \n2 0.294\nVariance function:\n Structure: Different standard deviations per stratum\n Formula: ~1 | trait \n Parameter estimates:\n      av1       av2 \n1.0000000 0.7442721 \nFixed effects:  value ~ 0 + trait + dv1:trait \n                Value Std.Error   DF   t-value p-value\ntraitav1     55.97952 0.6442894 1593  86.88568       0\ntraitav2     56.13836 0.3219135 1593 174.38959       0\ntraitav1:dv1  1.24557 0.0325430 1593  38.27480       0\ntraitav2:dv1  0.81125 0.0236929 1593  34.24036       0\n Correlation: \n             tratv1 tratv2 trt1:1\ntraitav2     -0.633              \ntraitav1:dv1  0.000  0.000       \ntraitav2:dv1  0.000  0.000  0.243\n\nStandardized Within-Group Residuals:\n        Min          Q1         Med          Q3         Max \n-4.14677763 -0.70322170  0.02487244  0.65471196  2.78718461 \n\nNumber of Observations: 1600\nNumber of Groups: 4 \n```\n:::\n\n```{.r .cell-code}\n#sjPlot::tab_model(model_1)\n\n\n# lme(value ~ 0 + trait + dv1:trait, \n#     random = ~ 0 + trait |group, \n#     weights = varIdent(form = ~ 1|trait), \n#     corr = corSymm(form = ~ as.numeric(trait)|group/id), \n#     data = dat2\n# )\n```\n:::\n\n\nVariation of this model:\n\nBy standardizing the dependent variable before calculating the models (\\`value \\<- scale(value)\\`), the main effects depict the standardized deviation from the overall mean of both variables and following that, the statistical test (se,t,p) represent the deviation of the mean of a variable from the overall mean.\n\n## MCMCglmm solution (most accurate)\n\nThe Bayesian solution by means of Markov-Chain Monte-Carlo glmm is able to take variable variances (random slopes) and variable intercorrelations of the dvs into account.\n\nThe model sometimes fails, asking for a better prior. Usually a rerun will fit the model (as the priors are set randomly as an iteration starting point). Here I chose a seed to make it work.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(MCMCglmm)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: Matrix\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'Matrix'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: coda\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: ape\n```\n:::\n\n```{.r .cell-code}\nset.seed(12322)\nmodel_2 <- MCMCglmm(cbind(av1, av2) ~ 0 + trait + dv1:trait, random = ~us(trait):id, rcov = ~us(trait):units, data = dat, family = c(\"gaussian\", \"gaussian\"), verbose = FALSE)\nsummary(model_2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n Iterations = 3001:12991\n Thinning interval  = 10\n Sample size  = 1000 \n\n DIC: -506.2845 \n\n G-structure:  ~us(trait):id\n\n                     post.mean l-95% CI u-95% CI eff.samp\ntraitav1:traitav1.id   31.9930  29.2626  35.3370  454.946\ntraitav2:traitav1.id   -3.1208  -3.6026  -2.7050    7.048\ntraitav1:traitav2.id   -3.1208  -3.6026  -2.7050    7.048\ntraitav2:traitav2.id    0.3063   0.2519   0.4008    3.961\n\n R-structure:  ~us(trait):units\n\n                        post.mean l-95% CI u-95% CI eff.samp\ntraitav1:traitav1.units     6.987    5.949    8.063    44.63\ntraitav2:traitav1.units    11.830   10.412   13.137    96.42\ntraitav1:traitav2.units    11.830   10.412   13.137    96.42\ntraitav2:traitav2.units    20.101   18.247   22.101   900.90\n\n Location effects: cbind(av1, av2) ~ 0 + trait + dv1:trait \n\n             post.mean l-95% CI u-95% CI eff.samp  pMCMC    \ntraitav1       55.9822  55.4701  56.4032   1160.2 <0.001 ***\ntraitav2       56.1362  55.8311  56.4564   1000.0 <0.001 ***\ntraitav1:dv1    1.1856   1.1252   1.2410   1113.3 <0.001 ***\ntraitav2:dv1    0.8372   0.7932   0.8817    975.2 <0.001 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\n## Repeated measurements\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}