---
title: Multivariate multilevel analyses
subtitle: A hands on primer in R
author: JÃ¼rgen Wilbert
date: 2021/03/17
categories: 
  - statistics
  - R
  - multilevel
  - bayesian
  - nlme
  - MCMCglmm
abstract: A short description how to do Multivariate Multilevel Analyses in R with the `nlme` and
  `MCMCglmm` packages
---

# Problem

Most of our data have a multilevel structure. But "standard" Manova analyzes do not take a nested structure with various strata into account. What we need is a multivariate extension of the univariate multilevel regression approach.

Multivariate multilevel analyses has various subtypes depending on the assumptions of the intercorrelations and variance of the dependent variables (dvs).

In this paper by Ben Bolker (<https://rpubs.com/bbolker/3336>), five subtypes are described. Interestingly, the case \#1 assumes equal variance of all dvs and equal (positive ?) correlations among the dvs. In this case, is is very easy: A random slope model with the dvs turned into a new random slope categorical variable.\
When dvs have different variances, the models must be weighted by their variance and when the intercorrelation between the dvs varies, the intercorrelations of the residuals have to be fixed to take these variations into account.

One approach is a Bayesian analyses with a Markov-Chain Monte-Carlo method. There is a vignette of the MCMCglmm package that explains how to do these analyses more in detail ([\<https://cran.r-project.org/web/packages/MCMCglmm/vignettes/CourseNotes.pdf\>](https://cran.r-project.org/web/packages/MCMCglmm/vignettes/CourseNotes.pdf){.uri}). Note: This example is for repeated measures.

# A frequentist approach

Snijders and Bosker (2012) describe multivariate multilevel analyses and they provide an [R example](https://www.stats.ox.ac.uk/~snijders/ch16.r) on this webage <https://www.stats.ox.ac.uk/~snijders/mlbook.htm>.

> Page 284 of Snijders and Bosker 2012: "To represent the multivariate data in the multilevel approach, three nesting levels are used. The first level is that of the dependent variables indexed by â„=1,...,ğ‘š, the second level is that of the individuals ğ‘–=1,...,ğ‘›ğ‘—, and the third level is that of the groups, ğ‘—=1,...,ğ‘. So each measurement of a dependent variable on some individual is represented by a separate line in the data matrix, containing the values ğ‘–, ğ‘—, ğ‘—, ğ‘Œâ„ğ‘–ğ‘—, ğ‘¥1ğ‘–ğ‘—, and those of the other explanatory variables. The multivariate model is formulated as hierarchical linear model using the same trick as in Section 15.1.3. Dummy variables ğ‘‘1,...,ğ‘‘ğ‘š are used to indicate the dependent variables, just as in formula (14.2). Dummy variable ğ‘‘â„ is 1 or 0, depending on whether the data line refers to dependent variable ğ‘Œğ‘— or to one of the other dependent variables."

## A computational example

First we need an example dataset to work with. I want two criteria (av1 and av2) and one explanatory variable (dv1) nested within four groups

```{r include = FALSE}
library(tidyverse)
library(nlme)
```

```{r eaxmple_dataset}
set.seed(1234)
ncases <- 800
ngroups <- 4
dat <- list()
dat$id <- 1:ncases
dat$group <- rep_len(1:ngroups, ncases)
dat$av1 <- rnorm(ncases, 50, 10)
dat$av2 <- (dat$av1 + rnorm(ncases, 50, 10)) / 2
dat$dv1 <- (dat$av1 + dat$av2 + rnorm(ncases, 50, 10)) /3
dat$av1 <- dat$av1 + (dat$group / ngroups * 10)
dat$av2 <- dat$av2 + (dat$group / ngroups * 10)
dat$dv1 <- dat$dv1 + (dat$group / ngroups * 10)
dat$dv1 <- scale(dat$dv1, scale = FALSE)
#dat$id <- rep(1:ncases, ngroups)
#dat$obs <- 1:(ncases*ngroups)
dat <- as.data.frame(dat)

dat2 <- dat %>%
  pivot_longer(cols = c("av1", "av2"), names_to = "trait") %>%
  mutate(trait = as.factor(trait))

```

## Manova without nesting data structure

The simple Manova has some disadvantages here:

-   No nested data structure

-   Assumes all variances are equal (also: across all strata, which it does not take into account anyway).

-   Assumes all intercorrelations of the variables are equal (again also across all strata)

```{r}
model <- lm(cbind(av1+av2) ~ 1 + dv1, data = dat)
summary(model)
car::Anova(model, type = "III")
```

## Multilevel regression approach

The following analyses follow the example of Snijders and Bosker (2012, Chapter 16).

Note: Dropping the intercept will set the main effect predictors of the dummy variable to the mean of the first variable. Also, dropping the main effect of the variable for the interaction will have an analogues effect for the interactions: the interaction with the first variable is displayed (otherwise, the main effect would entail the interaction of the first - here dummy - category and the variable).\

```{r}
model_1 <- lme(value ~ 0 + trait + dv1:trait, random = ~ 0 + trait |group,
data = dat2)
summary(model_1)
```

```{r }
#with weighted variances
model_1b <- update(model_1,  weights=varIdent(form=~1|trait))
summary(model_1b)
```

```{r}
#correlation between dvs
model_1c <- update(model_1b, corr = corSymm(form = ~ as.numeric(trait)|group/id))

summary(model_1c)
#sjPlot::tab_model(model_1)


# lme(value ~ 0 + trait + dv1:trait, 
#     random = ~ 0 + trait |group, 
#     weights = varIdent(form = ~ 1|trait), 
#     corr = corSymm(form = ~ as.numeric(trait)|group/id), 
#     data = dat2
# )

```

Variation of this model:

By standardizing the dependent variable before calculating the models (\`value \<- scale(value)\`), the main effects depict the standardized deviation from the overall mean of both variables and following that, the statistical test (se,t,p) represent the deviation of the mean of a variable from the overall mean.

## MCMCglmm solution (most accurate)

The Bayesian solution by means of Markov-Chain Monte-Carlo glmm is able to take variable variances (random slopes) and variable intercorrelations of the dvs into account.

The model sometimes fails, asking for a better prior. Usually a rerun will fit the model (as the priors are set randomly as an iteration starting point). Here I chose a seed to make it work.

```{r}
library(MCMCglmm)
set.seed(12322)
model_2 <- MCMCglmm(cbind(av1, av2) ~ 0 + trait + dv1:trait, random = ~us(trait):id, rcov = ~us(trait):units, data = dat, family = c("gaussian", "gaussian"), verbose = FALSE)
summary(model_2)
```

## Repeated measurements
