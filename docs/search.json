[
  {
    "objectID": "posts/contrasts.html",
    "href": "posts/contrasts.html",
    "title": "Treatment vs. effect contrasts",
    "section": "",
    "text": "Example dataset\nCreate a random dataset with criteria y, predictors x1, x2 and gender.\n\ny and gender are correlated\ny and x1 are correlated only if gender is 1\ny and x2 are correlated only if gender is 1\nx1 and x2 are correlated\nx1 and x2 have an interaction effect on y only if gender is 1\n\n\nset.seed(1234)\nn &lt;- 2000\ngender &lt;- rep(0:1, each = n/2)\ny &lt;- sample(0:10, n, replace = TRUE) + gender * sample(0:10, n, replace = TRUE)\nx1 &lt;- sample(0:10, n, replace = TRUE) + gender * y\nx2 &lt;- x1 + sample(0:10, n, replace = TRUE) + gender * y\ny &lt;- y + (x1 &gt; median(x1) & x2 &gt; median(x2) & gender == 1) * sample(0:10, n, replace = TRUE) * 2\n\ndat &lt;- data.frame(y = y, x1 = x1, x2 = x2, gender = gender)\n\n\n\nDescriptives\n\nwmisc::nice_corrmatrix(dat, type = \"html\", numbered_columns = FALSE)\n\n\nCorrelation matrix.\n\n\nVariable\nn\nM\nSD\ny\nx1\nx2\ngender\n\n\n\n\ny\n2000\n11.67\n9.83\n-\n\n\n\n\n\nx1\n2000\n10.09\n6.80\n.79***\n-\n\n\n\n\nx2\n2000\n20.30\n12.88\n.82***\n.95***\n-\n\n\n\ngender\n2000\n0.50\n0.50\n.68***\n.74***\n.79***\n-\n\n\n\nNote: \n\n\n\n\n\n\n\n\n\n ✝p &lt; .10; *p &lt; .05; **p &lt; .01; ***p &lt; .001\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nContrasts\nThe left part of the table is with gender as treatment contrast (0 vs. 1) and the right part with gender as effect contrast (-1 vs. 1)\n\n# Gender has values 0 vs. 1 (treatment contrast)\nfit1 &lt;- lm(y ~ gender * x1 * x2, data = dat)\n\n# Gender hast -1 vs. 1 (effect contrast)\ndat$gender &lt;- car::recode(dat$gender, \"0 = -1; 1 = 1\")\n\nfit2 &lt;- lm(y ~ gender * x1 * x2, data = dat)\n\nsjPlot::tab_model(fit1, fit2, show.se = TRUE, show.ci = FALSE, col.order = c(\"est\", \"se\", \"std.est\", \"p\"), digits = 4, dv.labels = c(\"Treatment contrast&lt;br&gt; for gender\", \"Effect contrast&lt;br&gt; for gender\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n \nTreatment contrast\nfor gender\nEffect contrast\nfor gender\n\n\nPredictors\nEstimates\nstd. Error\np\nEstimates\nstd. Error\np\n\n\n(Intercept)\n5.2577\n0.6189\n&lt;0.001\n-4.6274\n0.6427\n&lt;0.001\n\n\ngender\n-19.7703\n1.2853\n&lt;0.001\n-9.8852\n0.6427\n&lt;0.001\n\n\nx1\n-0.0695\n0.1358\n0.609\n0.6640\n0.0851\n&lt;0.001\n\n\nx2\n-0.0270\n0.0795\n0.734\n0.4363\n0.0482\n&lt;0.001\n\n\ngender × x1\n1.4671\n0.1702\n&lt;0.001\n0.7335\n0.0851\n&lt;0.001\n\n\ngender × x2\n0.9267\n0.0963\n&lt;0.001\n0.4633\n0.0482\n&lt;0.001\n\n\nx1 × x2\n0.0056\n0.0116\n0.629\n-0.0124\n0.0059\n0.036\n\n\n(gender × x1) × x2\n-0.0360\n0.0118\n0.002\n-0.0180\n0.0059\n0.002\n\n\nObservations\n2000\n2000\n\n\nR2 / R2 adjusted\n0.738 / 0.737\n0.738 / 0.737\n\n\n\n\n\n\n\n\nThe intercept in model1 (treatment contrast) is the mean of y for gender 0\nThe intercept in model2 (effect contrast) is the mean of y for all data\nAll predictors in model1 without a gender term are effects for gender 0 while the interactions with a gender term are effects for gender 1\nAll predictors in model2 without a gender term are effects across gender while the interactions with a gender term are the effects of gender (subtracted for gender 0 and added for gender 1).\ngender has a significant effect on y in both models\nx1, x2 and x1*x2 only have a significant effect on y in model 2\nAll gender interactions are significant in both models where the effect sizes and the standard errors of model2 are half of the corresponding values in model1, so p is identical.\n\n\n\nFor those who love Anovas ;-)\n\nfit1  |&gt; car::Anova(type = \"III\") |&gt; wmisc::nice_table()\n\n\n\n\n\nSum Sq\nDf\nF value\nPr(&gt;F)\n\n\n\n\n(Intercept)\n1834.702440\n1\n72.1670347\n0.0000000\n\n\ngender\n6014.888596\n1\n236.5924110\n0.0000000\n\n\nx1\n6.660056\n1\n0.2619697\n0.6088269\n\n\nx2\n2.943411\n1\n0.1157775\n0.7336959\n\n\ngender:x1\n1889.686051\n1\n74.3297855\n0.0000000\n\n\ngender:x2\n2352.201418\n1\n92.5225789\n0.0000000\n\n\nx1:x2\n5.937356\n1\n0.2335427\n0.6289624\n\n\ngender:x1:x2\n235.982758\n1\n9.2822550\n0.0023442\n\n\nResiduals\n50642.613736\n1992\nNA\nNA\n\n\n\n\n\n\n\n\nfit2  |&gt; car::Anova(type = \"III\") |&gt; wmisc::nice_table()\n\n\n\n\n\nSum Sq\nDf\nF value\nPr(&gt;F)\n\n\n\n\n(Intercept)\n1318.0715\n1\n51.845636\n0.0000000\n\n\ngender\n6014.8886\n1\n236.592411\n0.0000000\n\n\nx1\n1548.5771\n1\n60.912449\n0.0000000\n\n\nx2\n2085.6571\n1\n82.038201\n0.0000000\n\n\ngender:x1\n1889.6861\n1\n74.329785\n0.0000000\n\n\ngender:x2\n2352.2014\n1\n92.522579\n0.0000000\n\n\nx1:x2\n112.2512\n1\n4.415342\n0.0357425\n\n\ngender:x1:x2\n235.9828\n1\n9.282255\n0.0023442\n\n\nResiduals\n50642.6137\n1992\nNA\nNA"
  },
  {
    "objectID": "posts/2021-04-19.html",
    "href": "posts/2021-04-19.html",
    "title": "Create Rmarkdown webpage on gitHub",
    "section": "",
    "text": "Create a new R Project:\nFile -&gt; New Project -&gt; New Directory -&gt; Simple Rmarkdown website\nOpen new project\nActivate “git” versioning for this project (tools -&gt; project Options -&gt; Git/SVN)\nEdit the YAML file _site.yml:\nadd the line: `output_dir: “docs”``\nBuild website: Build -&gt; Build all\nChange to Github Desktop\nAdd repository: File -&gt; Add local repository\nClick: Publish repository\nOpen Github in Webbrowser and login\nGo to the new published repository\nClick Settings\nGo to menu Pages or scroll to Github Pages\nAt the field “Source” select master\nChange select folder from \\(root) to \\docs\nclick save\nCopy / remember / open the link to the new webpage that opens up! 16 Change to webpage project at RStudio\nCommit and publish all files [tab] Git -&gt; Commit\nChange to the new webpage address you remembered/copied or opened! (probably wait 30 seconds and renew the page)\n\nThat’s it!"
  },
  {
    "objectID": "posts/eRm.html",
    "href": "posts/eRm.html",
    "title": "eRm",
    "section": "",
    "text": "Keywords: irt, Rasch, eRm"
  },
  {
    "objectID": "posts/eRm.html#extract",
    "href": "posts/eRm.html#extract",
    "title": "eRm",
    "section": "Extract",
    "text": "Extract\n\npp_a &lt;- person.parameter(fit_a)\npp_d &lt;- person.parameter(fit_d)\n\ndat$pp_d &lt;- coef(pp_d) # add person parameter to raw data frame\ndat$pp_a &lt;- coef(pp_a) # add person parameter to raw data frame\n\nCaution! Raw values of 0 and 15 (upper and lower limit) are between -Inf/+Inf and the upper/lower cut off and are estimated based on the distribution shape.\n\nplot(pp_d, main = \"Dekodierungsleistung\")\n\n\n\nplot(pp_a, main = \"Automatisierung\")\n\n\n\n\n\nplotPImap(fit_d)"
  },
  {
    "objectID": "posts/eRm.html#visual-inspection-of-item-discrimination",
    "href": "posts/eRm.html#visual-inspection-of-item-discrimination",
    "title": "eRm",
    "section": "Visual inspection of item discrimination",
    "text": "Visual inspection of item discrimination\n\nplotjointICC(fit_d, xlim = c(-5, 5))\n\n\n\nplotjointICC(fit_a, xlim = c(-5, 5))"
  },
  {
    "objectID": "posts/eRm.html#likelihood-ratio-tests",
    "href": "posts/eRm.html#likelihood-ratio-tests",
    "title": "eRm",
    "section": "Likelihood ratio tests",
    "text": "Likelihood ratio tests\nLRtests test for the estimation “stability” across several sub-samples of the data set.\nA median split allows for checking if the item-difficulty estimations are constant for the lower and upper part of the performance scale. This is similar to a test for homoscedasticity.\n\nlr_d &lt;- LRtest(fit_d, splitcr = \"median\")\nlr_a &lt;- LRtest(fit_a, splitcr = \"median\")\n\nlr_d\n\n\nAndersen LR-test: \nLR-value: 6.954 \nChi-square df: 14 \np-value:  0.936 \n\nlr_a\n\n\nAndersen LR-test: \nLR-value: 17.088 \nChi-square df: 14 \np-value:  0.252 \n\n\n\nplotGOF(lr_d, conf= list())\n\n\n\nplotGOF(lr_a, ctrline= list())"
  },
  {
    "objectID": "posts/eRm.html#item-in-fit-out-fit",
    "href": "posts/eRm.html#item-in-fit-out-fit",
    "title": "eRm",
    "section": "Item In-Fit / Out Fit",
    "text": "Item In-Fit / Out Fit\nItemFit interpretation:\n\nlarger 2.0: Distorts or degrades the measurementsystem\n1.5-2.0: Unproductive for construction of measurement, but not degrading\n0.5-1.5: Productive for measurement\n&lt;0.5: Lessproductive for measurement, but not degrading. May produce misleadingly good reliabilities and separations\n\n\nitemfit(pp_d)\n\n\nItemfit Statistics: \n               Chisq df p-value Outfit MSQ Infit MSQ Outfit t Infit t Discrim\nD_01_Als      60.546 44   0.049      1.345     1.212    1.276   1.287   0.360\nD_02_Jan      55.231 44   0.119      1.227     1.163    0.846   0.950   0.397\nD_03_und      26.844 44   0.981      0.597     0.731   -1.722  -1.791   0.713\nD_04_Michael  42.051 44   0.555      0.934     0.931   -0.171  -0.382   0.569\nD_05_zum      46.485 44   0.370      1.033     1.029    0.211   0.232   0.490\nD_06_Schulhof 43.466 44   0.494      0.966     0.988   -0.040  -0.021   0.527\nD_07_kommen   45.764 44   0.399      1.017     1.036    0.153   0.277   0.462\nD_08_stehen   38.572 44   0.703      0.857     0.932   -0.491  -0.375   0.558\nD_09_die      52.715 44   0.173      1.171     1.064    0.697   0.444   0.457\nD_10_meisten  36.926 44   0.766      0.821     0.907   -0.634  -0.515   0.571\nD_11_aus      33.483 44   0.876      0.744     0.815   -0.945  -1.106   0.637\nD_12_der      33.313 44   0.880      0.740     0.892   -0.947  -0.652   0.569\nD_13_Klasse   57.032 44   0.090      1.267     1.124    1.027   0.792   0.417\nD_14_schon    47.227 44   0.342      1.049     0.937    0.273  -0.344   0.560\nD_15_da       57.058 44   0.090      1.268     1.174    1.036   1.068   0.382\n\nitemfit(pp_a)\n\n\nItemfit Statistics: \n                Chisq df p-value Outfit MSQ Infit MSQ Outfit t Infit t Discrim\nA_01_Als       63.799 45   0.034      1.387     1.123    1.244   0.785   0.432\nA_02_Jan       44.536 45   0.491      0.968     1.006    0.018   0.090   0.544\nA_03_und       49.213 45   0.308      1.070     1.164    0.330   1.037   0.427\nA_04_Michael   35.200 45   0.853      0.765     0.889   -0.765  -0.672   0.601\nA_05_zum       62.154 45   0.046      1.351     1.290    1.163   1.735   0.334\nA_06_Schulhof  40.073 45   0.680      0.871     1.017   -0.354   0.157   0.534\nA_07_kommen    22.361 45   0.998      0.486     0.640   -2.086  -2.575   0.783\nA_08_stehen    28.876 45   0.970      0.628     0.823   -1.268  -1.104   0.655\nA_09_die       41.513 45   0.620      0.902     0.878   -0.245  -0.759   0.625\nA_10_meisten   40.687 45   0.655      0.885     0.899   -0.278  -0.584   0.589\nA_11_aus       34.902 45   0.861      0.759     0.929   -0.772  -0.395   0.591\nA_12_der       39.471 45   0.705      0.858     0.891   -0.347  -0.621   0.582\nA_13_Klasse    33.062 45   0.906      0.719     0.884   -0.933  -0.693   0.610\nA_14_schon     51.039 45   0.248      1.110     1.110    0.456   0.718   0.470\nA_15_da       103.787 45   0.000      2.256     1.387    3.192   2.191   0.239"
  },
  {
    "objectID": "posts/eRm.html#person-in-fit-out-fit",
    "href": "posts/eRm.html#person-in-fit-out-fit",
    "title": "eRm",
    "section": "Person In-Fit / Out Fit",
    "text": "Person In-Fit / Out Fit\nPersonfit interpretation:\n\nlarger 2.0: Distorts or degrades the measurementsystem\n1.5-2.0: Unproductive for construction of measurement, but not degrading\n0.5-1.5: Productive for measurement\n&lt;0.5: Lessproductive for measurement, but not degrading. May produce misleadingly good reliabilities and separations\n\n\npersonfit(pp_d)\n\n\nPersonfit Statistics: \n     Chisq df p-value Outfit MSQ Infit MSQ Outfit t Infit t\nP3  18.927 14   0.168      1.262     1.049     0.61    0.27\nP5  15.238 14   0.362      1.016     1.015     0.22    0.21\nP6  14.437 14   0.418      0.962     1.000     0.27    0.30\nP7  13.111 14   0.518      0.874     0.945    -0.19   -0.02\nP8  15.300 14   0.358      1.020     1.012     0.17    0.13\nP9  13.724 14   0.470      0.915     0.982     0.04    0.15\nP10 14.481 14   0.415      0.965     0.991    -0.03    0.06\nP11 17.025 14   0.255      1.135     1.058     0.55    0.30\nP12 15.999 14   0.313      1.067     1.043     0.39    0.29\nP13 18.603 14   0.181      1.240     1.098     0.69    0.37\nP14 14.437 14   0.418      0.962     1.000     0.27    0.30\nP15 13.724 14   0.470      0.915     0.982     0.04    0.15\nP16 15.778 14   0.327      1.052     1.035     0.27    0.22\nP17 13.620 14   0.478      0.908     0.960    -0.10    0.02\nP18 15.606 14   0.338      1.040     1.041     0.59    0.59\nP19 13.829 14   0.463      0.922     0.957    -0.18   -0.07\nP20 15.778 14   0.327      1.052     1.035     0.27    0.22\nP21 13.658 14   0.475      0.911     0.936    -0.40   -0.29\nP22 13.922 14   0.456      0.928     0.926    -1.01   -1.05\nP23 13.165 14   0.514      0.878     0.880    -1.77   -1.76\nP24 13.396 14   0.496      0.893     0.919    -0.49   -0.39\nP25 14.991 14   0.379      0.999     1.000     0.02    0.03\nP26 13.170 14   0.513      0.878     0.880    -1.77   -1.76\nP27 15.468 14   0.347      1.031     1.021     0.29    0.22\nP28 16.349 14   0.293      1.090     1.067     0.74    0.60\nP29 14.214 14   0.434      0.948     0.953    -0.72   -0.68\nP30 16.024 14   0.312      1.068     1.063     0.95    0.93\nP31 15.018 14   0.377      1.001     1.007     0.07    0.10\nP32 14.503 14   0.413      0.967     0.975    -0.02    0.00\nP33 14.440 14   0.417      0.963     0.968    -0.26   -0.23\nP34 17.361 14   0.237      1.157     1.109     0.62    0.47\nP35 14.218 14   0.434      0.948     0.955    -0.20   -0.18\nP36 14.667 14   0.401      0.978     0.973     0.08    0.06\nP37 13.428 14   0.493      0.895     0.966     0.00    0.12\nP38 15.561 14   0.341      1.037     1.014     0.25    0.14\nP39 14.890 14   0.386      0.993     0.985     0.03   -0.02\nP40 17.319 14   0.240      1.155     1.049     0.45    0.27\nP41 16.305 14   0.295      1.087     1.036     0.34    0.25\nP42 14.612 14   0.405      0.974     1.005     0.28    0.30\nP43  9.352 14   0.808      0.623     0.923    -0.16    0.21\nP44 15.099 14   0.371      1.007     1.021     0.15    0.18\nP45 15.065 14   0.374      1.004     1.005     0.09    0.09\nP46 16.332 14   0.294      1.089     1.020     0.40    0.32\nP47 16.305 14   0.295      1.087     1.036     0.34    0.25\nP48 18.262 14   0.195      1.217     1.034     0.53    0.34\n\npersonfit(pp_a)\n\n\nPersonfit Statistics: \n     Chisq df p-value Outfit MSQ Infit MSQ Outfit t Infit t\nP4  12.220 14   0.589      0.815     0.980     0.11    0.27\nP5   8.725 14   0.848      0.582     0.911    -0.21    0.19\nP6  14.450 14   0.417      0.963     1.011     0.14    0.20\nP7  16.258 14   0.298      1.084     0.981     0.34    0.15\nP8  13.671 14   0.475      0.911     0.999     0.22    0.30\nP9  13.088 14   0.520      0.873     0.937    -0.34   -0.15\nP10  8.725 14   0.848      0.582     0.911    -0.21    0.19\nP11 14.977 14   0.380      0.998     0.996     0.01   -0.02\nP12 14.291 14   0.428      0.953     1.000     0.02    0.13\nP13 16.408 14   0.289      1.094     1.082     0.50    0.48\nP14 16.279 14   0.297      1.085     1.040     0.34    0.26\nP15 12.310 14   0.581      0.821     0.957    -0.12    0.10\nP16 19.363 14   0.152      1.291     1.057     0.65    0.29\nP17 18.928 14   0.168      1.262     1.122     0.72    0.43\nP18 12.792 14   0.543      0.853     0.867    -1.06   -1.04\nP19 15.592 14   0.339      1.039     1.022     0.26    0.22\nP20 14.411 14   0.420      0.961     0.988    -0.12    0.00\nP21 12.136 14   0.595      0.809     0.814    -2.18   -2.21\nP22 14.732 14   0.397      0.982     0.980    -0.16   -0.20\nP23 13.039 14   0.523      0.869     0.884    -0.93   -0.89\nP24 14.846 14   0.389      0.990     0.995    -0.08   -0.02\nP25 13.750 14   0.468      0.917     0.909    -0.90   -1.02\nP26 16.428 14   0.288      1.095     1.096     1.03    1.08\nP27 13.448 14   0.492      0.897     0.899    -1.13   -1.16\nP28 15.995 14   0.314      1.066     1.070     0.38    0.42\nP29 13.976 14   0.451      0.932     0.940    -0.45   -0.43\nP30 16.719 14   0.271      1.115     1.111     1.22    1.25\nP31 17.110 14   0.250      1.141     1.117     1.01    0.90\nP32 16.487 14   0.285      1.099     1.094     1.07    1.07\nP33 12.345 14   0.579      0.823     0.845    -0.83   -0.78\nP34 13.757 14   0.468      0.917     0.921    -0.56   -0.58\nP35 17.053 14   0.253      1.137     1.119     0.99    0.92\nP36 15.893 14   0.320      1.060     1.063     0.66    0.73\nP37 15.219 14   0.363      1.015     1.031     0.15    0.20\nP38 14.328 14   0.426      0.955     1.007     0.27    0.30\nP39 15.560 14   0.341      1.037     1.048     0.22    0.26\nP40 15.269 14   0.360      1.018     1.014     0.15    0.14\nP41 14.119 14   0.441      0.941     0.951    -0.10   -0.09\nP42 13.641 14   0.477      0.909     0.965    -0.09    0.04\nP43 17.825 14   0.215      1.188     1.071     0.50    0.31\nP44 12.803 14   0.542      0.854     0.989     0.15    0.28\nP45 20.151 14   0.125      1.343     1.050     0.64    0.35\nP46 20.151 14   0.125      1.343     1.050     0.64    0.35\nP47 11.101 14   0.678      0.740     0.910    -0.29    0.02\nP48 20.151 14   0.125      1.343     1.050     0.64    0.35\nP49 20.152 14   0.125      1.343     1.050     0.64    0.35"
  },
  {
    "objectID": "posts/multivariate_multilevel.html",
    "href": "posts/multivariate_multilevel.html",
    "title": "Multivariate multilevel analyses",
    "section": "",
    "text": "Most of our data have a multilevel structure. But “standard” Manova analyzes do not take a nested structure with various strata into account. What we need is a multivariate extension of the univariate multilevel regression approach.\nMultivariate multilevel analyses has various subtypes depending on the assumptions of the intercorrelations and variance of the dependent variables (dvs).\nIn this paper by Ben Bolker (https://rpubs.com/bbolker/3336), five subtypes are described. Interestingly, the case #1 assumes equal variance of all dvs and equal (positive ?) correlations among the dvs. In this case, is is very easy: A random slope model with the dvs turned into a new random slope categorical variable.\nWhen dvs have different variances, the models must be weighted by their variance and when the intercorrelation between the dvs varies, the intercorrelations of the residuals have to be fixed to take these variations into account.\nOne approach is a Bayesian analyses with a Markov-Chain Monte-Carlo method. There is a vignette of the MCMCglmm package that explains how to do these analyses more in detail (&lt;https://cran.r-project.org/web/packages/MCMCglmm/vignettes/CourseNotes.pdf&gt;). Note: This example is for repeated measures."
  },
  {
    "objectID": "posts/multivariate_multilevel.html#a-computational-example",
    "href": "posts/multivariate_multilevel.html#a-computational-example",
    "title": "Multivariate multilevel analyses",
    "section": "A computational example",
    "text": "A computational example\nFirst we need an example dataset to work with. I want two criteria (av1 and av2) and one explanatory variable (dv1) nested within four groups\n\nset.seed(1234)\nncases &lt;- 800\nngroups &lt;- 4\ndat &lt;- list()\ndat$id &lt;- 1:ncases\ndat$group &lt;- rep_len(1:ngroups, ncases)\ndat$av1 &lt;- rnorm(ncases, 50, 10)\ndat$av2 &lt;- (dat$av1 + rnorm(ncases, 50, 10)) / 2\ndat$dv1 &lt;- (dat$av1 + dat$av2 + rnorm(ncases, 50, 10)) /3\ndat$av1 &lt;- dat$av1 + (dat$group / ngroups * 10)\ndat$av2 &lt;- dat$av2 + (dat$group / ngroups * 10)\ndat$dv1 &lt;- dat$dv1 + (dat$group / ngroups * 10)\ndat$dv1 &lt;- scale(dat$dv1, scale = FALSE)\n#dat$id &lt;- rep(1:ncases, ngroups)\n#dat$obs &lt;- 1:(ncases*ngroups)\ndat &lt;- as.data.frame(dat)\n\ndat2 &lt;- dat %&gt;%\n  pivot_longer(cols = c(\"av1\", \"av2\"), names_to = \"trait\") %&gt;%\n  mutate(trait = as.factor(trait))"
  },
  {
    "objectID": "posts/multivariate_multilevel.html#manova-without-nesting-data-structure",
    "href": "posts/multivariate_multilevel.html#manova-without-nesting-data-structure",
    "title": "Multivariate multilevel analyses",
    "section": "Manova without nesting data structure",
    "text": "Manova without nesting data structure\nThe simple Manova has some disadvantages here:\n\nNo nested data structure\nAssumes all variances are equal (also: across all strata, which it does not take into account anyway).\nAssumes all intercorrelations of the variables are equal (again also across all strata)\n\n\nmodel &lt;- lm(cbind(av1+av2) ~ 1 + dv1, data = dat)\nsummary(model)\n\n\nCall:\nlm(formula = cbind(av1 + av2) ~ 1 + dv1, data = dat)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-30.0270  -5.3806   0.1014   5.6296  24.7045 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 112.1179     0.3033  369.69   &lt;2e-16 ***\ndv1           2.0226     0.0430   47.04   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.578 on 798 degrees of freedom\nMultiple R-squared:  0.735, Adjusted R-squared:  0.7346 \nF-statistic:  2213 on 1 and 798 DF,  p-value: &lt; 2.2e-16\n\ncar::Anova(model, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: cbind(av1 + av2)\n              Sum Sq  Df  F value    Pr(&gt;F)    \n(Intercept) 10056336   1 136672.2 &lt; 2.2e-16 ***\ndv1           162828   1   2212.9 &lt; 2.2e-16 ***\nResiduals      58717 798                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "posts/multivariate_multilevel.html#multilevel-regression-approach",
    "href": "posts/multivariate_multilevel.html#multilevel-regression-approach",
    "title": "Multivariate multilevel analyses",
    "section": "Multilevel regression approach",
    "text": "Multilevel regression approach\nThe following analyses follow the example of Snijders and Bosker (2012, Chapter 16).\nNote: Dropping the intercept will set the main effect predictors of the dummy variable to the mean of the first variable. Also, dropping the main effect of the variable for the interaction will have an analogues effect for the interactions: the interaction with the first variable is displayed (otherwise, the main effect would entail the interaction of the first - here dummy - category and the variable).\n\n\nmodel_1 &lt;- lme(value ~ 0 + trait + dv1:trait, random = ~ 0 + trait |group,\ndata = dat2)\nsummary(model_1)\n\nLinear mixed-effects model fit by REML\n  Data: dat2 \n       AIC      BIC    logLik\n  9937.194 9980.196 -4960.597\n\nRandom effects:\n Formula: ~0 + trait | group\n Structure: General positive-definite, Log-Cholesky parametrization\n         StdDev    Corr  \ntraitav1 1.2311183 tratv1\ntraitav2 0.5143689 -0.816\nResidual 5.3422224       \n\nFixed effects:  value ~ 0 + trait + dv1:trait \n                Value Std.Error   DF   t-value p-value\ntraitav1     55.97952 0.6438845 1593  86.94032       0\ntraitav2     56.13836 0.3190894 1593 175.93303       0\ntraitav1:dv1  1.24563 0.0292196 1593  42.62999       0\ntraitav2:dv1  0.81402 0.0279074 1593  29.16883       0\n Correlation: \n             tratv1 tratv2 trt1:1\ntraitav2     -0.628              \ntraitav1:dv1  0.000  0.000       \ntraitav2:dv1  0.000  0.000 -0.038\n\nStandardized Within-Group Residuals:\n        Min          Q1         Med          Q3         Max \n-4.69589000 -0.66817031  0.02572767  0.63497999  3.13414812 \n\nNumber of Observations: 1600\nNumber of Groups: 4 \n\n\n\n#with weighted variances\nmodel_1b &lt;- update(model_1,  weights=varIdent(form=~1|trait))\nsummary(model_1b)\n\nLinear mixed-effects model fit by REML\n  Data: dat2 \n       AIC      BIC    logLik\n  9870.822 9919.199 -4926.411\n\nRandom effects:\n Formula: ~0 + trait | group\n Structure: General positive-definite, Log-Cholesky parametrization\n         StdDev    Corr  \ntraitav1 1.2103832 tratv1\ntraitav2 0.5547227 -0.774\nResidual 6.0607475       \n\nVariance function:\n Structure: Different standard deviations per stratum\n Formula: ~1 | trait \n Parameter estimates:\n      av1       av2 \n1.0000000 0.7442685 \nFixed effects:  value ~ 0 + trait + dv1:trait \n                Value Std.Error   DF   t-value p-value\ntraitav1     55.97952 0.6420068 1593  87.19460       0\ntraitav2     56.13836 0.3199433 1593 175.46347       0\ntraitav1:dv1  1.24415 0.0329916 1593  37.71123       0\ntraitav2:dv1  0.81271 0.0239648 1593  33.91260       0\n Correlation: \n             tratv1 tratv2 trt1:1\ntraitav2     -0.632              \ntraitav1:dv1  0.000  0.000       \ntraitav2:dv1  0.000  0.000 -0.037\n\nStandardized Within-Group Residuals:\n        Min          Q1         Med          Q3         Max \n-4.13902014 -0.69797783  0.02637369  0.64981098  2.76937510 \n\nNumber of Observations: 1600\nNumber of Groups: 4 \n\n\n\n#correlation between dvs\nmodel_1c &lt;- update(model_1b, corr = corSymm(form = ~ as.numeric(trait)|group/id))\n\nsummary(model_1c)\n\nLinear mixed-effects model fit by REML\n  Data: dat2 \n       AIC      BIC    logLik\n  9800.954 9854.707 -4890.477\n\nRandom effects:\n Formula: ~0 + trait | group\n Structure: General positive-definite, Log-Cholesky parametrization\n         StdDev    Corr  \ntraitav1 1.2152290 tratv1\ntraitav2 0.5592672 -0.832\nResidual 6.0605912       \n\nCorrelation Structure: General\n Formula: ~as.numeric(trait) | group/id \n Parameter estimate(s):\n Correlation: \n  1    \n2 0.294\nVariance function:\n Structure: Different standard deviations per stratum\n Formula: ~1 | trait \n Parameter estimates:\n      av1       av2 \n1.0000000 0.7442721 \nFixed effects:  value ~ 0 + trait + dv1:trait \n                Value Std.Error   DF   t-value p-value\ntraitav1     55.97952 0.6442894 1593  86.88568       0\ntraitav2     56.13836 0.3219135 1593 174.38959       0\ntraitav1:dv1  1.24557 0.0325430 1593  38.27480       0\ntraitav2:dv1  0.81125 0.0236929 1593  34.24036       0\n Correlation: \n             tratv1 tratv2 trt1:1\ntraitav2     -0.633              \ntraitav1:dv1  0.000  0.000       \ntraitav2:dv1  0.000  0.000  0.243\n\nStandardized Within-Group Residuals:\n        Min          Q1         Med          Q3         Max \n-4.14677763 -0.70322170  0.02487244  0.65471196  2.78718461 \n\nNumber of Observations: 1600\nNumber of Groups: 4 \n\n#sjPlot::tab_model(model_1)\n\n\n# lme(value ~ 0 + trait + dv1:trait, \n#     random = ~ 0 + trait |group, \n#     weights = varIdent(form = ~ 1|trait), \n#     corr = corSymm(form = ~ as.numeric(trait)|group/id), \n#     data = dat2\n# )\n\nVariation of this model:\nBy standardizing the dependent variable before calculating the models (`value &lt;- scale(value)`), the main effects depict the standardized deviation from the overall mean of both variables and following that, the statistical test (se,t,p) represent the deviation of the mean of a variable from the overall mean."
  },
  {
    "objectID": "posts/multivariate_multilevel.html#mcmcglmm-solution-most-accurate",
    "href": "posts/multivariate_multilevel.html#mcmcglmm-solution-most-accurate",
    "title": "Multivariate multilevel analyses",
    "section": "MCMCglmm solution (most accurate)",
    "text": "MCMCglmm solution (most accurate)\nThe Bayesian solution by means of Markov-Chain Monte-Carlo glmm is able to take variable variances (random slopes) and variable intercorrelations of the dvs into account.\nThe model sometimes fails, asking for a better prior. Usually a rerun will fit the model (as the priors are set randomly as an iteration starting point). Here I chose a seed to make it work.\n\nlibrary(MCMCglmm)\n\nLoading required package: Matrix\n\n\n\nAttaching package: 'Matrix'\n\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\n\nLoading required package: coda\n\n\nLoading required package: ape\n\nset.seed(12322)\nmodel_2 &lt;- MCMCglmm(cbind(av1, av2) ~ 0 + trait + dv1:trait, random = ~us(trait):id, rcov = ~us(trait):units, data = dat, family = c(\"gaussian\", \"gaussian\"), verbose = FALSE)\nsummary(model_2)\n\n\n Iterations = 3001:12991\n Thinning interval  = 10\n Sample size  = 1000 \n\n DIC: -506.2845 \n\n G-structure:  ~us(trait):id\n\n                     post.mean l-95% CI u-95% CI eff.samp\ntraitav1:traitav1.id   31.9930  29.2626  35.3370  454.946\ntraitav2:traitav1.id   -3.1208  -3.6026  -2.7050    7.048\ntraitav1:traitav2.id   -3.1208  -3.6026  -2.7050    7.048\ntraitav2:traitav2.id    0.3063   0.2519   0.4008    3.961\n\n R-structure:  ~us(trait):units\n\n                        post.mean l-95% CI u-95% CI eff.samp\ntraitav1:traitav1.units     6.987    5.949    8.063    44.63\ntraitav2:traitav1.units    11.830   10.412   13.137    96.42\ntraitav1:traitav2.units    11.830   10.412   13.137    96.42\ntraitav2:traitav2.units    20.101   18.247   22.101   900.90\n\n Location effects: cbind(av1, av2) ~ 0 + trait + dv1:trait \n\n             post.mean l-95% CI u-95% CI eff.samp  pMCMC    \ntraitav1       55.9822  55.4701  56.4032   1160.2 &lt;0.001 ***\ntraitav2       56.1362  55.8311  56.4564   1000.0 &lt;0.001 ***\ntraitav1:dv1    1.1856   1.1252   1.2410   1113.3 &lt;0.001 ***\ntraitav2:dv1    0.8372   0.7932   0.8817    975.2 &lt;0.001 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "posts/multivariate_multilevel.html#repeated-measurements",
    "href": "posts/multivariate_multilevel.html#repeated-measurements",
    "title": "Multivariate multilevel analyses",
    "section": "Repeated measurements",
    "text": "Repeated measurements"
  },
  {
    "objectID": "posts/git-github/index.html",
    "href": "posts/git-github/index.html",
    "title": "Setup a new github / Rstudio project",
    "section": "",
    "text": "Start a new RStudio Project\nTools –&gt; Project Options –&gt; Git/SVN: Set Version Control System to Git\nCommit a first file\nChange to Github Desktop\nFile –&gt; Add local repository: Add the new project folder\nOn the main screen click: Add/push repository to git (or similar)\nGive the repository a name: et voilà!\n\nOptional:\nChange to Rstudio\nPull and Push committed files"
  },
  {
    "objectID": "posts/2023-06-21/index.html",
    "href": "posts/2023-06-21/index.html",
    "title": "Logits as a link function in logistic regressions",
    "section": "",
    "text": "If you estimate a dichotomous outcome variable \\(y\\) (\\(y\\) can take the values 0 or 1) with a standard ols (ordinary least squares) regression the distribution of \\(y\\) does not meet ols regression assumptions. Specifically, predicted values can be outside \\(\\{0, 1\\}\\) and are not continuous and normal distributed. A common solution for this problem is to apply a generalization of the linear regression model which is (surprise, surprise) called the generalized linear model (GLM). One aspect of the generalized linear model is that the linear combination of the predictors (linear because we assume that the added up predictors are interval scaled) are linked to the distribution of the outcome variable via a function which is called: the link function (uhhh).\nIt is helpful to keep in mind that for dichotomous variables, we estimate/predict the probabilities that \\(y=1\\). That is, the predicted values are probabilities of \\([0, 1]\\) (a continuous interval between 0 and 1) and not \\(\\{0, 1\\}\\) (either 0 or 1). Therefore, we are looking for a link function that turns the linear combined predictors into a probability estimation. In case of a logistic regression, we need a formula, that turns continuous values from \\([-\\infty, +\\infty]\\) to a probability (where \\(0\\) corresponds to a 50% probability) and vise-versa, a probability into a continuous scale with values from \\([-\\infty, +\\infty]\\). This transformation is called a logit transformation and the distribution of the transformed predicted \\(y\\) values is a logistic distribution. This kind of function (i.e. a function that links the distribution of linear combinations of the predictors to the distribution of the criteria in a regression) is called a link function."
  },
  {
    "objectID": "posts/2023-06-21/index.html#problem-and-solution",
    "href": "posts/2023-06-21/index.html#problem-and-solution",
    "title": "Logits as a link function in logistic regressions",
    "section": "",
    "text": "If you estimate a dichotomous outcome variable \\(y\\) (\\(y\\) can take the values 0 or 1) with a standard ols (ordinary least squares) regression the distribution of \\(y\\) does not meet ols regression assumptions. Specifically, predicted values can be outside \\(\\{0, 1\\}\\) and are not continuous and normal distributed. A common solution for this problem is to apply a generalization of the linear regression model which is (surprise, surprise) called the generalized linear model (GLM). One aspect of the generalized linear model is that the linear combination of the predictors (linear because we assume that the added up predictors are interval scaled) are linked to the distribution of the outcome variable via a function which is called: the link function (uhhh).\nIt is helpful to keep in mind that for dichotomous variables, we estimate/predict the probabilities that \\(y=1\\). That is, the predicted values are probabilities of \\([0, 1]\\) (a continuous interval between 0 and 1) and not \\(\\{0, 1\\}\\) (either 0 or 1). Therefore, we are looking for a link function that turns the linear combined predictors into a probability estimation. In case of a logistic regression, we need a formula, that turns continuous values from \\([-\\infty, +\\infty]\\) to a probability (where \\(0\\) corresponds to a 50% probability) and vise-versa, a probability into a continuous scale with values from \\([-\\infty, +\\infty]\\). This transformation is called a logit transformation and the distribution of the transformed predicted \\(y\\) values is a logistic distribution. This kind of function (i.e. a function that links the distribution of linear combinations of the predictors to the distribution of the criteria in a regression) is called a link function."
  },
  {
    "objectID": "posts/2023-06-21/index.html#the-logit-transformation",
    "href": "posts/2023-06-21/index.html#the-logit-transformation",
    "title": "Logits as a link function in logistic regressions",
    "section": "The logit transformation",
    "text": "The logit transformation\nThe formula to turn probabilities into continuous values (here logits) is:\n\\[logit(y_i)=log(\\frac{P(y_i=1)}{1-P(y_i=0)})=log(odds)\\]\nHere is the function plot for illustration with probabilities on x and logits on y:\n\n\nCode\n# identical: plot(function(x) qlogis(x))\nplot(function(x) log(x/(1-x)))\n\n\n\n\n\nLogit/logistic function\n\n\n\n\nThe formula to turn continuous values (here logits) into probabilities is:\n\\[P(y_i=1)=\\frac{exp(x)}{1 + exp(x)}\\]\nHere is the function plot for illustration with logits on x and probablities on y:\n\n\nCode\n# identica: plot(function(x) plogis(x), -6,6)\nplot(function(x) exp(x)/(1 + exp(x)), from = -6, to = 6)\n\n\n\n\n\nDistribution of the logistic function (invers logistic)"
  },
  {
    "objectID": "posts/2023-06-21/index.html#what-are-logits",
    "href": "posts/2023-06-21/index.html#what-are-logits",
    "title": "Logits as a link function in logistic regressions",
    "section": "What are logits?",
    "text": "What are logits?\nLogits are the logarithm of the odds of a probability \\(log(Odds)\\). Odds is a way to represent the probability of an event: If the odds are four against one (\\(4\\over1\\)), than out of 5 events, 4 have one category of outcome and 1 has an opposite outcome (for example, if a horse runs five races and we expect that it will win four races and loose one, the odds are \\(4\\over1\\)). If the odds are &lt; 1, the probability of an event is below 50%. For example, if the odds are 0.25 = \\(\\frac{1}{4}\\) we expect that the horse will win one out of five races.\n\n\n\n\n\n\nCaution\n\n\n\nCaution: Probabilities and odds can be confused easily but are not identical. A probability of \\(1\\over4\\) would index that a specific outcome happens in 1 out of 4 events, whereas odds of \\(1\\over4\\) would index that an event has the probability for two possible outcomes of 1 against 4. For this example, odds of \\(1\\over4\\) equals a probability of \\(1\\over5\\) equals \\(0.20\\).\n\n\nThe odds are calculated as:\n\\[Odds(y_i)=\\frac{P(y_i=1)}{1-P(y_i=0)}\\]\nFor example, if we have a probability of 25%, the odds are:\n\\[Odds=\\frac{0.25}{0.75}={1\\over3}\\]\nThe formula for calculating logits is:\n\\[logit(y_i)=log(\\frac{P(y_i=1)}{1-P(y_i=0)})=log(odds)\\]\nFor example, if we have a 25% probability that is:\n\\[logit(P=0.25)=log(\\frac{0.25}{0.75})=log({1\\over3})=-1.098612\\]"
  },
  {
    "objectID": "posts/2023-06-21/index.html#example",
    "href": "posts/2023-06-21/index.html#example",
    "title": "Logits as a link function in logistic regressions",
    "section": "Example",
    "text": "Example\nTo be continued 😉"
  },
  {
    "objectID": "posts/contrasts/index.html",
    "href": "posts/contrasts/index.html",
    "title": "Contrasts in single-cases",
    "section": "",
    "text": "plottable\n\n\n\n\n\n\n\n\n\n\n\n\nSingle case data frame with 1 cases\n\n\n\n\n\n\n\n\nPawel\n\n\n\nvalues\nmt\nphase\n\n\n\n\n10\n1\nA1\n\n\n19\n2\nA1\n\n\n11\n3\nA1\n\n\n6\n4\nA1\n\n\n16\n5\nA1\n\n\n16\n6\nA1\n\n\n17\n7\nA1\n\n\n18\n8\nA1\n\n\n12\n9\nA1\n\n\n12\n10\nA1\n\n\n39\n11\nB1\n\n\n18\n12\nB1\n\n\n25\n13\nB1\n\n\n31\n14\nB1\n\n\n29\n15\nB1\n\n\n24\n16\nB1\n\n\n37\n17\nB1\n\n\n17\n18\nB1\n\n\n21\n19\nB1\n\n\n18\n20\nB1\n\n\n16\n21\nA2\n\n\n17\n22\nA2\n\n\n19\n23\nA2\n\n\n21\n24\nA2\n\n\n10\n25\nA2\n\n\n11\n26\nA2\n\n\n23\n27\nA2\n\n\n11\n28\nA2\n\n\n10\n29\nA2\n\n\n9\n30\nA2\n\n\n34\n31\nB2\n\n\n35\n32\nB2\n\n\n28\n33\nB2\n\n\n30\n34\nB2\n\n\n22\n35\nB2\n\n\n21\n36\nB2\n\n\n21\n37\nB2\n\n\n22\n38\nB2\n\n\n23\n39\nB2\n\n\n34\n40\nB2\n\n\n\n\n\n\n\n\n\n\n\n# dataset:\ndf &lt;- as.data.frame(exampleA1B1A2B2$Pawel)\ndf$mt &lt;- df$mt - df$mt[1]\n\n# mean of all phases\n\n(means &lt;- tapply(df$values, df$phase, mean))\n  A1   B1   A2   B2 \n13.7 25.9 14.7 27.0 \n(grand_mean &lt;- mean(means))\n[1] 20.325\n\n\n# Plm function reference:\nplm(exampleA1B1A2B2$Pawel, contrast = \"first\", trend = FALSE, slope = FALSE) %&gt;% coef() %&gt;% .[,1]\n\n(Intercept)     phaseB1     phaseA2     phaseB2 \n       13.7        12.2         1.0        13.3 \n\nplm(exampleA1B1A2B2$Pawel, contrast = \"preceding\", trend = FALSE, slope = FALSE) %&gt;% coef() %&gt;% .[,1]\n\n(Intercept)     phaseB1     phaseA2     phaseB2 \n       13.7        12.2       -11.2        12.3"
  },
  {
    "objectID": "posts/contrasts/index.html#treatment-contrast",
    "href": "posts/contrasts/index.html#treatment-contrast",
    "title": "Contrasts in single-cases",
    "section": "Treatment contrast",
    "text": "Treatment contrast\nCompare mean of second to last phase against first phase (intercept)\nThe Intercept is the mean of a reference phase (defaults to the first).\nThe predictors are the differences from a phase to the reference (intercept).\n\ntreatment &lt;- contr.treatment(4)\ncolnames(treatment) &lt;- c(\"B1vsA1\",\"A2vsA1\",\"B2vsA1\")\ntreatment\n\n  B1vsA1 A2vsA1 B2vsA1\n1      0      0      0\n2      1      0      0\n3      0      1      0\n4      0      0      1\n\nlm(values~phase, data=df, contrasts = list(phase = treatment)) |&gt; coef()\n\n(Intercept) phaseB1vsA1 phaseA2vsA1 phaseB2vsA1 \n       13.7        12.2         1.0        13.3 \n\nc(Intercept = 13.7, # phaseA1\n  phaseB1vsA1 = 25.9 - 13.7, \n  phaseA2vsA1 = 14.7 - 13.7,\n  phaseB2vsA1 = 27 - 13.7)\n\n  Intercept phaseB1vsA1 phaseA2vsA1 phaseB2vsA1 \n       13.7        12.2         1.0        13.3"
  },
  {
    "objectID": "posts/contrasts/index.html#sum-contrast",
    "href": "posts/contrasts/index.html#sum-contrast",
    "title": "Contrasts in single-cases",
    "section": "Sum contrast",
    "text": "Sum contrast\nComparison from the first to the second last phase with the overall mean (Intercept is overall mean)\nThe Intercept is the overall mean.\nThe predictors are the differences from a phase mean to the overall mean.\n\nsum &lt;- contr.sum(4)\ncolnames(sum) &lt;- c(\"A1vsMean\",\"B1vsMean\",\"A2vsMean\")\nsum\n\n  A1vsMean B1vsMean A2vsMean\n1        1        0        0\n2        0        1        0\n3        0        0        1\n4       -1       -1       -1\n\nlm(values~phase, data=df, contrasts = list(phase = sum)) |&gt; coef()\n\n  (Intercept) phaseA1vsMean phaseB1vsMean phaseA2vsMean \n       20.325        -6.625         5.575        -5.625 \n\nc(Intercept = grand_mean,\n  phaseA1vsMean = 13.7 - grand_mean, \n  phaseB1vsMean = 25.9 - grand_mean, \n  phaseA2vsMean = 14.7 - grand_mean)\n\n    Intercept phaseA1vsMean phaseB1vsMean phaseA2vsMean \n       20.325        -6.625         5.575        -5.625"
  },
  {
    "objectID": "posts/contrasts/index.html#helmert-contrast",
    "href": "posts/contrasts/index.html#helmert-contrast",
    "title": "Contrasts in single-cases",
    "section": "Helmert contrast",
    "text": "Helmert contrast\nCompares from the second to the last phase with the mean of all preceding phases.\nThe Intercept is the overall mean.\nThe predictors are the mean differences from a phase mean to the mean of all preceding phases.\n\nhelmert &lt;- contr.helmert(4)\ncolnames(helmert) &lt;- c(\"B1vsA1\", \"A2vsA1_B1\", \"B2vsA1_B1_A2\")\nhelmert\n\n  B1vsA1 A2vsA1_B1 B2vsA1_B1_A2\n1     -1        -1           -1\n2      1        -1           -1\n3      0         2           -1\n4      0         0            3\n\nlm(values~phase, data=df, contrasts = list(phase = helmert)) |&gt; coef()\n\n      (Intercept)       phaseB1vsA1    phaseA2vsA1_B1 phaseB2vsA1_B1_A2 \n           20.325             6.100            -1.700             2.225 \n\nc(Intercept = grand_mean,\n  phaseB1vsA1 = (25.9 + -13.7) / 2, \n  phaseA2vsA1_B1 = (14.7  + (-13.7-25.9)/2) / 3,\n  phaseB2vsA1_B1_A2 = (27 + (-13.7-25.9-14.7)/3) /4)\n\n        Intercept       phaseB1vsA1    phaseA2vsA1_B1 phaseB2vsA1_B1_A2 \n           20.325             6.100            -1.700             2.225"
  },
  {
    "objectID": "posts/contrasts/index.html#revert-helmert",
    "href": "posts/contrasts/index.html#revert-helmert",
    "title": "Contrasts in single-cases",
    "section": "Revert Helmert",
    "text": "Revert Helmert\nComparing the second to last phase against the mean of all preceding phases\nThe Intercept is the grand mean.\nThe predictors are the differences from a phase to the mean of the preeding phases.\nCompare phase2 vs. phase 1, phase 3 vs. mean of phase 1 and 2, phase4 vs. mean of phases 1,2,3 (Intercept is overall mean)\n\nrevers_helmert &lt;- matrix(c(-1/2, 1/2, 0, 0, -1/3, -1/3, 2/3, 0, -1/4, -1/4, -1/4, 3/4), ncol = 3)\ncolnames(revers_helmert) &lt;- c(\"B1vsA1\", \"A2vsA1_B1\", \"B2vsA1_B1_A2\")\nrevers_helmert\n\n     B1vsA1  A2vsA1_B1 B2vsA1_B1_A2\n[1,]   -0.5 -0.3333333        -0.25\n[2,]    0.5 -0.3333333        -0.25\n[3,]    0.0  0.6666667        -0.25\n[4,]    0.0  0.0000000         0.75\n\nlm(values~phase, data=df, contrasts = list(phase = revers_helmert)) |&gt; coef()\n\n      (Intercept)       phaseB1vsA1    phaseA2vsA1_B1 phaseB2vsA1_B1_A2 \n           20.325            12.200            -5.100             8.900 \n\nc(Intercept = grand_mean,\n  phaseB1vsA1 = 25.7 - 13.7,\n  phaseA2vsA1_B1 = 14.7 - (13.7+25.9)/2,\n  phaseB2vsA1_B1_A2 = 27 - (13.7+25.9+14.7)/3)\n\n        Intercept       phaseB1vsA1    phaseA2vsA1_B1 phaseB2vsA1_B1_A2 \n           20.325            12.000            -5.100             8.900"
  },
  {
    "objectID": "posts/contrasts/index.html#cummulative",
    "href": "posts/contrasts/index.html#cummulative",
    "title": "Contrasts in single-cases",
    "section": "Cummulative",
    "text": "Cummulative\nCompare mean of second to last phase to mean of preceding phase\nThe Intercept is the mean of the first phase.\nThe predictors are the differences from a phase to the preeding phase.\n\ncumulative &lt;- matrix(c(0,1,1,1, 0,0,1,1, 0,0,0,1), ncol = 3)\ncolnames(cumulative) &lt;- c(\"B1vsA1\",\"A2vsB1\",\"B2vsA2\")\ncumulative\n\n     B1vsA1 A2vsB1 B2vsA2\n[1,]      0      0      0\n[2,]      1      0      0\n[3,]      1      1      0\n[4,]      1      1      1\n\nlm(values~phase, data=df, contrasts = list(phase = cumulative)) |&gt; coef()\n\n(Intercept) phaseB1vsA1 phaseA2vsB1 phaseB2vsA2 \n       13.7        12.2       -11.2        12.3 \n\nc(Intercept = 13.7,\n  phaseB1vsA1 = 25.9 - 13.7, \n  phaseA2vsB1 = 14.7 - 25.9,\n  phaseB2vsA2 = 27 - 14.7)\n\n  Intercept phaseB1vsA1 phaseA2vsB1 phaseB2vsA2 \n       13.7        12.2       -11.2        12.3"
  },
  {
    "objectID": "course_R_intro.html",
    "href": "course_R_intro.html",
    "title": "Courses: Introduction to data analysis with R",
    "section": "",
    "text": "Courses: Introduction to data analysis with R\n\n\nSession 1: Introduction\n\n\nSlides: Introduction\n\n\nSession 1b: RStudio\n\n\n\n\nSession 2: Basics: Datatypes\n\n\nSlides: Basics\n\n\nSession 3: Sophisticated subsetting\n\n\nSlides: Sophisticated subsetting\n\n\nSession 4: Libraries, projects, and importing data\n\n\nSlides: Libraries, projects, and importing data\nExample file: cars.xlsx\n\n\nSession 5: Rmarkdown\n\n\nSlides: Rmarkdown\n\n\nSession 6: tidyverse\n\n\nSlides: Rmarkdown\n\n\nSession 7: Data preparation with dplyr\n\n\nSlides: dplyr\n\n\nSession 8: Graphics with gpplot2\n\n\nSlides: ggplot2"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Active projects\n\nESPENQLB-DISISDYNAMIKSiKLedUEREP Uganda\n\n\n\n\n\n\n\n\n\nTitle\nEmotional, social, and psychological development in inclusive primary schools\n\n\n\nOriginal: Emotionale, soziale und psychische Entwicklung an der inklusiven Grundschule\n\n\nTeam\nThomas Hennemann; Jürgen Wilbert\nJohanna Krull; Karolina Urton; Jannis Bosch; Ella Baer\n\n\nHomepage\nNot available\n\n\nTerm\n1.9.2021 - 31.8.2024\n\n\nFunding\nSchool district Mettmann, Germany\n\n\n\n\n\n\n\n\nTitle\nDiagnostic of internalizing psychological problems in schools\n\n\n\nOriginal: Diagnostik internalisierender Störungen an der inklusiven Schule\n\n\nTeam\nJürgen Wilbert; Jannnis Bosch; Ella Baer\n\n\nHomepage\nProject homepage\n\n\nTerm\n1.2.2021 - 30.12.2023\n\n\nFunding\nFederal Ministry of Education and Research - BMBF\n\n\n\n\n\n\n\n\nTitle\nDynamic testing as a perspective for intervention oriented diagnostic decisions\n\n\n\nOriginal: Dynamisches Testen als Perspektive für förderdiagnostische Entscheidungen in der Schule\n\n\nTeam\nMoritz Börnert-Ringleb; Claudia Mähler; Jürgen Wilbert; Julia Küttner; Linda Kuhr\n\n\nHomepage\nhttp:://www.dynamik-projekt.de\n\n\nTerm\n1.11.2021 - 31.10.2024\n\n\nFunding\nFederal Ministry of Education and Research - BMBF\n\n\n\n\n\n\n\n\nTitle\nProcess monitoring and support of language education in inclusive classes\n\n\n\nOriginal: Sprachbildungsprozesse in inklusiven Klassen im Lernverlauf diagnostizieren und unterstützen\n\n\nTeam\nMarkus Linnemann; Gabriele Kniffka; Petra Gretsch; Jürgen Wilbert\n\n\nHomepage\nNot available\n\n\nTerm\n1.11.2021 - 31.10.2024\n\n\nFunding\nFederal Ministry of Education and Research - BMBF\n\n\n\n\n\n\n\n\n\n\n\n\nTitle\nEducational Research on Educational Participation in Uganda\n\n\nTeam\nMichel Knigge; Wolfgang Lauterbach; Jürgen Wilbert\n\n\nHomepage\nNot available\n\n\nTerm\nsince 2019\n\n\n\n\n\n\n\n\n\nCompleted projects\n\nKOMPASSMettmann 20QLB-PSI DiagnostikMettmann\n\n\n\n\n\nTitle\nCooperative behavior modification and computer-based-training for students with behavioral and academic problems\n\n\n\nOriginal: Kooperative Verhaltensmodifikation und PC-basierte Förderung bei Verhaltensauffälligkeiten und Schulschwierigkeiten\n\n\nTeam\nMichael von Aster; Christian Huber; Gerd Schulte-Körne; Jürgen Wilbert\nLinda Kuhr; Moritz Börnert (see homepage for full list)\n\n\nHomepage\nProject homepage\n\n\nTerm\n1.10.2018 - 30.9.2021\n\n\nFunding\nFederal Ministry of Education and Research - BMBF\n\n\n\n\n\n\n\n\nTitle\nSchool on its way to inclusion\n\n\n\nOriginal: Mettmann 20: Schule auf dem Weg zur Inklusion\n\n\nTeam\nThomas Hennemann; Jürgen Wilbert\nJohanna Krull; Karolina Urton (see homepage for full list)\n\n\nHomepage\nProject homepage\n\n\nTerm\n1.11.2016 - 31.10.2020\n\n\nFunding\nSchool district Mettmann, Germany\n\n\n\n\n\n\n\n\nTitle\nDiagnostic competences of teachers in inclusive classes\n\n\n\nOriginal: Diagnostische Kompetenz von Lehrkräften im inklusiven Unterricht\n\n\nTeam\nJürgen Wilbert; Jana Grubert; Lynn Scherreiks\n\n\nHomepage\nProject homepage\n\n\nTerm\n1.9.2015 - 31.8.2019\n\n\nFunding\nFederal Ministry of Education and Research - BMBF\n\n\n\n\n\n\n\n\n\n\n\n\nTitle\nInclusive school development\n\n\n\nOriginal: Wissenschaftliche Begleitung zur inklusiven Schulentwicklung im Kreis Mettmann\n\n\nTeam\nThomas Hennemann; Clemens Hillenbrand\nJohanna Krull; Karlina Urton; Jürgen Wilbert\n\n\nTerm\n1.8.2012 - 30.7.2015\n\n\nFunding\nSchool district Mettmann, Germany"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Homepage Jürgen Wilbert",
    "section": "",
    "text": "Hello!\n\nThis is the centre of all my web activities, a place where anyone interested in my work can start.\nMy name is Jürgen Wilbert. I am a Professor of Research Methods and Diagnostics at the Department of Inclusive Education at the University of Potsdam in Germany. I studied education at the University of Cologne, where I also did my doctorate in cognitive psychology. I then obtained a permanent position as a senior researcher at the Department of Special Education. I later habilitated at the Carl-von-Osietzky University of Oldenburg on the topic of “Pedagogy and Psychology in Learning Disabilities”.\nMy work focuses on:\n\nSingle-case research designs, analysis of single-case data, and reporting of single-case based results.\nSocial inclusion and social participation the classroom.\nImplementation of Open Science and Data Science concepts in special education research."
  },
  {
    "objectID": "students.html",
    "href": "students.html",
    "title": "Graduate Students",
    "section": "",
    "text": "Completed PhD students\n\n\n\n\n\n\n\n\nName\nField\nGraduation\n\n\n\n\nProf. Dr. Karolina Urton\nInclusive school development\n2016\n\n\nDr. Johanna Krull\nSocial Inclusion\n2018\n\n\nProf. Dr. Moritz Börnert-Ringleb\nDynamic Testing\n2018\n\n\nDr. Pawel Kulawiak\nSociometric data analyzes\n2020\n\n\nDr. Jannis Bosch\nSocial comparison and interest development\n2020\n\n\n\n\n\nPresent PhD students\n\n\n\n\n\n\n\n\nName\nField\nStarted\n\n\n\n\nAnja Schwalbe\nSocial norms in inclusive classrooms\n2014\n\n\nLinda Kuhr\nMath anxiety\n2018\n\n\nElla Baer\nDiagnosing students’ internalization problems in the classroom\n2020\n\n\nAnte Pavic\n\n2022\n\n\nLydia Küttner\n\n2022"
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Publications",
    "section": "",
    "text": "Updated 2023-06-12\n\nJournal papers\n\nUrton, K., Wilbert, J., Krull, J., & Hennemann, T. (accepted). Factors Explaining Teachers’ Intention to Implement Inclusive Practices in the Classroom: Indications Based on the Theory of Planned Behaviour. Teaching and Teacher Education.\nBosch, J., & Wilbert, J. (2023). The Impact of Social Comparison Processes on Self-Evaluation of Performance, Self-Concept, and Task Interest. Frontiers in Education: Educational Psychology.\nKrull, J., Urton, K., Kulawiak, P. R., Wilbert, J., & Hennemann, T. (2022). Social-relational classroom climate and its link to primary students’ behavioral problems. Empirische Sonderpädagogik, 24(2), 22.\nLeidig, T., Casale, G., Wilbert, J., Hennemann, T., Volpe, R. J., Briesch, A., & Grosche, M. (2022). Individual, generalized, and moderated effects of the good behavior game on at-risk primary school students: A multilevel multiple baseline study using behavioral progress monitoring. Frontiers in Education, 7. https://doi.org/10.3389/feduc.2022.917138\nWilbert, J., Lüke, T., & Börnert-Ringleb, M. (2022). Statistical Power of Piecewise Regression Analyses of Single-Case Experimental Studies Addressing Behavior Problems. Frontiers in Education Educational Psychology, 7. https://doi.org/10.3389/feduc.2022.917944\nSchmidt, H., Felisatti, A., von Aster, M., Wilbert, J., von Moers, A., & Fischer, M. H. (2021). Neuromuscular Diseases Affect Number Representation and Processing: An Exploratory Study. Frontiers in Psychology, 12, 3710. https://doi.org/10.3389/fpsyg.2021.697881\nSchwalbe, A., Müller, C. M., & Wilbert, J. (2021). Wahrgenommene Gruppennormen und ihre Bedeutung für die soziale Akzeptanz und Ablehnung in Grundschulklassen. Zeitschrift für Grundschulforschung. https://doi.org/10.1007/s42278-021-00107-w\nWilbert, J., Bosch, J., & Lüke, T. (2021). Validity and judgement bias in visual analysis of single-case data. International Journal for Research in Learning Disabilities, 5(1), 13–24. https://doi.org/10.28987/ijrld.5.1.13\nBörnert-Ringleb, M., & Wilbert, J. (2020). Die Vorhersage von Mathe- und Leseleistungen durch dynamisches Testen. Lernen und Lernstörungen, 1–12. https://doi.org/10.1024/2235-0977/a000331\nKulawiak, Pawel R., Wilbert, J., Schlack, R., & Börnert-Ringleb, M. (2020). Prediction of child and adolescent outcomes with broadband and narrowband dimensions of internalizing and externalizing behavior using the child and adolescent version of the Strengths and Difficulties Questionnaire. PLOS ONE, 15(10), e0240312. https://doi.org/10.1371/journal.pone.0240312\nDünkel, N., Knigge, M., & Wilbert, J. (2020). Determinanten und Akkuratheit von Schülerurteilen über sprachliche Fähigkeiten von Mitschüler(inne)n im Deutschen und den Herkunftssprachen Türkisch und Russisch. Zeitschrift für Erziehungswissenschaft. https://doi.org/10.1007/s11618-020-00972-8\nHoffmann, L., Wilbert, J., Lehofer, M., & Schwab, S. (2020). Are we good friends? – Friendship preferences and the quantity and quality of mutual friendships. European Journal of Special Needs Education, 36(4), 502–5016. https://doi.org/10.1080/08856257.2020.1769980\nBosch, J., & Wilbert, J. (2020). Contrast and Assimilation Effects on Self-Evaluation of Performance and Task Interest in a Sample of Elementary School Children. Frontiers in Education, 4. https://doi.org/10.3389/feduc.2019.00165\nKulawiak, P. R., Urton, K., Krull, J., Hennemann, T., & Wilbert, J. (2020). Internalizing Behaviour of Sociometrically Neglected Students in Inclusive Primary Classrooms - A Methodological Issue? Frontiers in Education, 5. https://doi.org/10.3389/feduc.2020.00032\nWilbert, J., Urton, K., Krull, J., Kulawiak, P. R., Schwalbe, A., & Hennemann, T. (2020). Teachers’ Accuracy in Estimating Social Inclusion of Students With and Without Special Educational Needs. Frontiers in Education, 5. https://doi.org/10.3389/feduc.2020.598330\nBörnert-Ringleb, M., & Wilbert, J. (2019). Beitrag eines dynamischen gegenüber einem statischen kognitiven Test zur Vorhersage der Schulleistung. Empirische Sonderpädagogik, 11(3), 175–190. https://doi.org/10.25656/01:17778\nKulawiak, Pawel R., & Wilbert, J. (2019). Introduction of a new method for representing the sociometric status within the peer group: the example of sociometrically neglected children. International Journal of Research & Method in Education, 1–19. https://doi.org/10.1080/1743727X.2019.1621830\nBörnert-Ringleb, M., & Wilbert, J. (2018). The Association of Strategy Use and Concrete-Operational Thinking in Primary School. Frontiers in Education, 3. https://doi.org/10.3389/feduc.2018.00038\nKrull, J., Wilbert, J., & Hennemann, T. (2018). Does social exclusion by classmates lead to behaviour problems and learning difficulties or vice versa? A cross-lagged panel analysis. European Journal of Special Needs Education, 33(2), 235–253. https://doi.org/10.1080/08856257.2018.1424780\nHennemann, T., Hillenbrand, C., Fitting-Dahlmann, K., Wilbert, J., & Urton, K. (2018). Auf dem Weg zum inklusiven Schulsystem im Kreis Mettmann – Konzeption der wissenschaftlichen Begleitevaluation. Zeitschrift für Heilpädagogik, 69(1), 4–16.\nKrull, J., Urton, K., Wilbert, J., & Hennemann, T. (2018). Der Kreis Mettmann auf dem Weg zum inklusiven Schulsystem – zentrale Ergebnisse der wissenschaftlichen Begleitung. Zeitschrift für Heilpädagogik, 69(1), 17–39.\nUrton, K., Börnert-Ringleb, M., Krull, J., Wilbert, J., & Hennemann, T. (2018). Inklusives Schulklima: Konzeptionelle Darstellung eines Rahmendmodells. Zeitschrift für Heilpädagogik, 69, 40–52.\nBosch, J., & Wilbert, J. (2017). Contrast and Assimilation Effects on Task Interest in an Academic Learning Task. Frontline Learning Research, 5(2), 60–78. https://doi.org/10.14786/flr.v5i2.292\nGrünke, M., Wilbert, J., Tsiriotakis, I. K., & Agirregoikoa, A. L. (2017). Improving the Length and Quality of Texts Written by Fourth Graders With Learning Disabilities Through a Peer-Tutoring Graphic Organizing Strategy. Insights into Learning Disabilities, 14(2), 167–188. https://eric.ed.gov/?q=Improving+the+Length+and+Quality+of+Texts+Written+by+Fourth+Graders+With+Learning+Disabilities+Through+a+Peer-Tutoring+Graphic+Organizing+Strategy.+Insights+into+Learning+Disabilities&id=EJ1164946\nHennemann, T., Casale, G., Wilbert, J., Grosche, M., Fitting-Dahlmann, K., Hövel, D., Hagen, T., Leidig, T., & Melzer, C. (2017). „Schulen auf dem Weg zur Inklusion” Konzeption, Evaluation und erste Befunde eines landesweiten Qualifizierungsprogrammes zur Umsetzung von Inklusion in Nordrhein-Westfalen. Zeitschrift für Heilpädagogik.\nWilbert, J., Urton, K., & Grubert, J. (2016). Entwicklung eines Verfahrens zur Messung des inklusionsspezifischen Selbstwirksamkeitserlebens im schulischen Kontext. Empirische Sonderpädagogik, 8(3), 289–302. https://doi.org/10.25656/01:12607\nUrton, K., Wilbert, J., Grosche, M., & Hennemann, T. (2016). Vergleich der beruflichen Interessenstruktur von Studierenden der Sonderpädagogik mit den Anforderungen des sonderpädagogischen Lehrerberufs. Zeitschrift für Bildungsforschung. https://doi.org/10.1007/s35834-016-0160-5\nBörnert, M., & Wilbert, J. (2016). Dynamisches Testen als neue Perspektive in der sonderpädagogischen Diagnostik - Theorie, Evidenzen, Impulse für Forschung und Praxis. Zeitschrift für Heilpädagogik, 67(4), 156–167.\nHintz, A.-M., Urton, K., Krull, J., Wilbert, J., & Hennemann, T. (2015). Teachers’ Perceptions of Opportunities and Threats Concerning Inclusive Schooling in Germany at an Early Stage of Inclusion: Analyses of a Mixed Methodology Approach. Journal of Cognitive Education and Psychology, 14(3), 357–374. https://doi.org/10.1891/1945-8959.14.3.357\nUrton, K., Wilbert, J., & Hennemann, T. (2015). Die Einstellung zur Integration und die Selbstwirksamkeit von Lehrkräften. Psychologie in Erziehung und Unterricht, 62(2), 147–157. https://doi.org/10.2378/peu2015.art09d\nBörnert, M., & Wilbert, J. (2015). Thinking-aloud protocols of Piagetian tasks: Insights into problem-solving processes of primary school students. Insights on Learning Disabilities, 12(1), 19–34.\nGrünke, M., Büyüknarci, Ö., Wilbert, J., & Breuer, Esther. (2015). To what extent do certain characteristics of a child’s written story influence the way it is rated? Insights into features necessary for supporting struggling writers. Insights into Learning Disabilities, 12(2), 163–177.\nKulawiak, Pawel R., & Wilbert, J. (2015). Methoden zur Analyse der sozialen Integration von Schulkindern mit sonderpädagogischem Förderbedarf im gemeinsamen Unterricht. Empirische Sonderpädagogik, 7(3), 241–257.https://doi.org/10.25656/01:11385\nRietz, C., & Wilbert, J. (Hrsg.). (2015). Schwerpunktthema: Best-Practice der Datenanalyse in sonderpädagogischen Forschungsfeldern. Empirische Sonderpädagogik, 7(3).\nKrull, J., Wilbert, J., & Hennemann, T. (2014a). Soziale Ausgrenzung von Erstklässlerinnen und Erstklässlern mit sonderpädagogischem Förderbedarf im Gemeinsamen Unterricht. Empirische Sonderpädagogik, 6(1), 59–75.\nKrull, J., Wilbert, J., & Hennemann, T. (2014b). The Social and Emotional Situation of First Graders with Classroom Behavior Problems and Classroom Learning Difficulties in Inclusive Classes. Learning Disabilities: A Contemporary Journal, 12(2), 169–190.\nLüke, T., Wilbert, J., Weichselbaum, M., & Grünke, M. (2014). Zur Sichtbarkeit der Fachzeitschrift „Empirische Sonderpädagogik” – Eine bibliometrische Analyse. Empirische Sonderpädagogik, 6(4), 363–370.\nUrton, K., Wilbert, J., & Hennemann, T. (2014a). Attitudes towards inclusion and self-efficacy of principals and teachers in German primary schools. Learning Disabilities: A Contemporary Journal, 12(2), 151–168.\nUrton, K., Wilbert, J., & Hennemann, T. (2014b). Der Zusammenhang zwischen der Einstellung zur Integration und der Selbstwirksamkeit von Schulleitungen und deren Kollegien. Empirische Sonderpädagogik, 6(1), 3–16.\nGrünke, M., Wilbert, J., & Stegemann-Calder, K. (2013). Analyzing the effects of story mapping on the reading comprehension of children with low intellectual abilities. Learning Disabilities: A Contemporary Journal, 11(2), 51–64.\nHuber, C., & Wilbert, J. (2012). Soziale Ausgrenzung von Schülern mit sonderpädagogischem Förderbedarf und niedrigen Schulleistungen im gemeinsamen Unterricht. Empirische Sonderpädagogik, 4(2), 147–165.\nWilbert, J., & Grosche, M. (2012). A dissociation of implicit and explicit spatial sequence learning in a group of students with learning difficulties. Journal of Cognitive Education and Psychology, 11(3), 301–316.\nWilbert, J., & Haider, H. (2012). The subjective experience of committed errors and the Discrepancy-Attribution hypothesis. Acta Psychologica, 139, 370–381. https://doi.org/10.1016/j.actpsy.2011.11.010\nWilbert, J. (2011). Die Einsetzbarkeit der Skalen zur Erfassung der Lern- und Leistungsmotivation (SELLMO) bei Schülern des Förderschwerpunkts Lernen. Zeitschrift für Heilpädagogik, 62, 11–17.\nWilbert, J., & Linnemann, M. (2011). Kriterien zur Analyse eines Tests zur Lernverlaufsdiagnostik. Empirische Sonderpädagogik, 3(3), 225–242.\nHennemann, T., Hillenbrand, C., Wilbert, J., Franke, S., Spieß, R., Jürgens, J., & Görgens, G. (2010). Kompetenzen und Risiken in der Transition in die Hauptschule - eine Querschnittsuntersuchung von Schülerinnen und Schülern der 5. Jahrgangsstufen. Empirische Sonderpädagogik, 2(4), 36–49.\nNeugebauer, U., & Wilbert, J. (2010). Zum Zusammenhang zwischen Bewältigungsstil und Burnout-Symptomen bei Lehrkräften der Förderschule Lernen. Empirische Sonderpädagogik, 2(3), 69–82.\nWilbert, J. (2010). Stereotype-Threat Effekte bei Schülern des Förderschwerpunkts Lernen. Heilpädagogische Forschung, 36(4), 154–161.\nWilbert, J., Grosche, M., & Gerdes, H. (2010). Effects of Evaluative Feedback on Rate of Learning and Task Motivation: An Analogue Experiment. Learning Disabilities: A Contemporary Journal, 8(1), 43–52.\nWilbert, J., & Grünke, M. (2010a). Ein Vergleich des Lehrerbildes von Schülern der Förderschule Lernen und der Regelschule. Heilpädagogische Forschung, 36(1), 2–14.\nWilbert, J., & Grünke, M. (2010b). Norms and goals of appraisal of German teachers for students with learning disabilities. Learning Disabilities: A Contemporary Journal, 8(2), 19–30.\nWilbert, J., & Gerdes, H. (2009). Die Bezugsnormwahl bei der Bewertung schulischer Leistungen durch angehende Lehrkräfte des Förderschwerpunktes Lernen. Heilpädagogische Forschung, 35, 122–135.\nWilbert, J., & Gerdes, H. (2007). Lehrerbild von Schülern und Lehrern: Eine empirische Studie zum Vergleich der Vorstellungen vom idealen und vom typischen Lehrer. Psychologie in Erziehung und Unterricht, 54(3), 208–222.\n\n\n\nBook chapters\n\nWilbert, J., & Lüke, T. (2023). Leistungsbewertung und Leistungsattribution. In M. Börnert-Ringleb, G. Casale, M. Balt, & M. Herzog (Eds.), Lern- und Verhaltensschwierigkeiten in der Schule—Erscheinungsformen, Erklärungsmodelle und Implikationen für die Praxis (pp. 167–176). Kohlhammer.\nGabriel, T., Börnert‐Ringleb, M. & Wilbert, J. (2022). Dynamisches Testen im Spannungsfeld von Selektion und Modifikation. In M. Gebhardt, D. Scheer & M. Schurig (Hrsg.), Handbuch der sonderpädagogischen Diagnostik. Grundlagen und Konzepte der Statusdiagnostik, Prozessdiagnostik und Förderplanung (p. 313‐322). Regensburg: Universitätsbibliothek. https://doi.org/10.5283/epub.53149\nScherreiks, L., Kuhr, L., & Wilbert, J. (2022). Veränderung der selbsteingeschätzten Kompetenz zur Diagnostik psychischer Auffälligkeiten im Psychodiagnostischen Praktikum. In J. Jennek (Ed.), Professionalisierung in Praxisphasen: Ergebnisse der Lehrerbildungsforschung an der Universität Potsdam (p. 23). Universitätsverlag Potsdam. DOI: 10.25932/publishup-50096\nWilbert, J., & Börnert, M. (2022). Unterricht. In I. Hedderich, G. Biewer, J. Hollenweger, & R. Markowetz (Hrsg.), Handbuch Inklusion und Sonderpädagogik (S. 346–353). 2. Auflage. Julius Klinkhardt.\nBörnert-Ringleb, M., & Wilbert, J. (2022). Verlaufsdiagnostik und einzelfallbasierte Veränderungsmessung im Rahmen schulischer Förderung. In Y. Blumenthal, S. Blumenthal, & K. Mahlau (Eds.), Kinder mit Lern- und emotional-sozialen Entwicklungsauffälligkeiten in der Schule (pp. 72–77). Kohlhammer.\nWilbert, J., & Krull, J. (2021). Die Bedeutung von Peers für die soziale Partizipation von Lernenden mit Lern- und Verhaltensproblemen in inklusiven Schulklassen. In M. Kreutzmann, L. Zander, & B. Hannover (Hrsg.), Aufwachsen mit Anderen. Peerbeziehungen als Bildungsfaktor (S. 134–152). Kohlhammer.\nBörnert-Ringleb, M., & Wilbert, J. (2021). Dynamisches Testen: Diagnostik als Möglichkeit der Modellierung von Kompetenzentwicklung. In C. Mähler & M. Hasselhorn (Hrsg.), Inklusionsherausforderungen. Hogrefe.\nScherreiks, L., Kuhr, L., & Wilbert, J. (2021). Veränderung der selbsteingeschätzten Kompetenz zur Diagnostik psychischer Auffälligkeiten im Psychodiagnostischen Praktikum.\nUrton, K., Wilbert, J., & Knigge, M. (2019). Die Entwicklung der Selbstwirksamkeit und des Rollenverständnisses während des Praxissemesters von Studierenden des Lehramtes für Sonderpädagogische Förderung. In D. Zimmermann, U. Fickler-Stang, L. Dietrich, & K. Weiland (Hrsg.), Professionalisierung für Unterricht und Beziehungsarbeit mit psychosozial beeinträchtigten Kindern und Jugendlichen (S. 145–157). Klinkhammer.\nUrton, K., Börnert-Ringleb, M., & Wilbert, J. (2018). Gestaltung eines inklusiven Schulklimas als Schulentwicklungsaufgabe. In F. Hellmich, G. Görel, & M. Löper (Hrsg.), Inklusive Schul- und Unterrichtsentwicklung. Kohlhammer.\nBörnert-Ringleb, M., Bosch, J., & Wilbert, J. (2018). Lernverlaufsdiagnostik. In M. Dziak-Mahler, T. Hennemann, S. Jaster, T. Leidig, & J. Springob (Hrsg.), Fachdidaktik inklusiv II - (Fach-)Unterricht inklusiv gestalten - Theoretische Annäherungen und praktische Umsetzungen. Waxmann Verlag.\nGrubert, J., Kulawiak, P. R., Schwalbe, A., Scherreiks, L., Börnert-Ringleb, M., & Wilbert, J. (2018). Fragebogen zur Erfassung diagnostischer Kompetenzen hinsichtlich psychischer Auffälligkeiten von Schüler_innen. In Potsdamer Beiträge zur Lehrerbildung und Bildungsforschung (S. 17–27). Universität Potsdam.\nGrubert, J., Schwalbe, A., Kulawiak, P. R., & Wilbert, J. (2018). Seminarkonzept zur Förderung inklusionsrelevanter Kompetenzen – Diagnostik hinsichtlich psychischer Auffälligkeiten von Schüler_innen. In Potsdamer Beiträge zur Lehrerbildung und Bildungsforschung (S. 125–124). Universität Potsdam.\nKulawiak, P. R., & Wilbert, J. (2018). Komplementäre Studiendesigns zur Evidenzbasierung in der Bildungswissenschaft. In R. Haring & J. Siegmüller (Hrsg.), Evidenzbasierte Praxis in den Gesundheitsberufen (S. 17–31). Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-662-55377-0_2\nBörnert, M., Grubert, J., & Wilbert, J. (2016). Lautes Denken als Methode zur Forschung und Diagnostik in inklusionspädagogischen Handlungsfeldern (D. Gebele & A. L. Zepter, Hrsg.; S. 165–186). Gilles & Francke Verlag.\nBosch, J., Schaefer, A., Kulawiak, P. R., & Wilbert, J. (2016). Forschungsdesigns zur Untersuchung kausaler Beziehungen in den empirischen Bildungswissenschaften (D. Gebele & A. L. Zepter, Hrsg.; S. 138–164). Gilles & Francke Verlag.\nWilbert, J. (2015). Streuung, Standardabweichung und Varianz. In S. Ellinger & K. Koch (Hrsg.), Forschungsmethoden in der Heil- und Sonderpädagogik (S. 129–136). Hogrefe.\nWilbert, J., & Grünke, M. (2015). Kontrollierte Einzelfallforschung. In S. Ellinger & K. Koch (Hrsg.), Forschungsmethoden in der Heil- und Sonderpädagogik (S. 100–105). Hogrefe.\nWilbert, J., & Börnert, M. (2015). Unterricht. In I. Hedderich, G. Biewer, J. Hollenweger, & R. Markowetz (Hrsg.), Handbuch Inklusion und Sonderpädagogik (S. 346–353). Julius Klinkhardt.\nLinnemann, M., & Wilbert, J. (2014). Do C-tests measure language comprehension of learning disabled students? In R. Grotjahn (Hrsg.), Der C-Test: Beiträge aus der aktuellen Forschung/ The C-Test: Contributions from Current Research (S. 223–238). Lang.\nWilbert, J. (2014a). Instrumente zur Lernverlaufsmessung. Gütekriterien und Auswertungsherausforderungen. In M. Hasselhorn, W. Schneider, & U. Trautwein (Hrsg.), Lernverlaufsdiagnostik (S. 281–308). Hogrefe.\nWilbert, J. (2014b). Lern- und Leistungsmotivation. In A. Castello (Hrsg.), Entwicklungsrisiken bei Kindern und Jugendlichen: Prävention im pädagogischen Alltag. Kohlhammer.\nWilbert, J. (2014c). Vermittlung von Basiskompetenzen zum Rechnen. In G. Lauth, M. Grünke, & J. Brunstein (Hrsg.), Interventionen bei Lernstörungen: Förderung, Training und Therapie in der Praxis (S. 209–219). Hogrefe.\nLinnemann, M., & Wilbert, J. (2010). The C-test: A valid instrument for screening language skills and reading comprehension of children with learning problems? In R. Grotjahn (Hrsg.), Der C-Test: Beiträge aus der aktuellen Forschung/ The C-Test: Contributions from Current Research (S. 113–124). Lang.\nGrünke, M., & Wilbert, J. (2008). Offener Unterricht und Projektunterricht. In M. Fingerle & S. Ellinger (Hrsg.), Sonderpädagogische Förderung: Förderkonzepte auf dem Prüfstand (S. 13–33). Kohlhammer.\n\n\n\nBooks and reports\n\nKuhr, L., Napiany, S., Huber, C., & Wilbert, J. (2021). Abschlussbericht F1-Projekt KOMPASS Standorte: Potsdam/ Wuppertal (S. 317). University of Potsdam and University of Wuppertal.\nKrull, J., Urton, K., Hennemann, T., & Wilbert, J. (2021). Mettmann 2.0 – Wissenschaftliche Begleitung auf dem Weg zum inklusiven Schulsystem des Kreises Mettmann Abschlussbericht (S. 68). University of Cologne.\nWilbert, J. (2022). Analyzing single-case data with R and scan. doi: 10.5281/zenodo.5713559. https://jazznbass.github.io/scan-Book/\nHennemann, T., Wilbert, J., & Hillenbrand, C. (2014). Wissenschaftliche Begleitung im Rahmen der Umsetzung zur inklusiven Schule im Kreis Mettmann (Mehrebenenanalyse 2010 – 2012). Abschlussbericht. Universität zu Köln.\nBecker-Mrotzek, M., Ehlich, K., Füssenich, I., Günther, H., Hasselhorn, M., Hopf, M., Jeuk, S., Lengyel, D., Neugebauer, U., Panagiotopoulou, A., Stanat, P., & Wilbert, J. (2013). Qualitätsmerkmale für Sprachstandsverfahren im Elementarbereich. Ein Bewertungsrahmen für fundierte Sprachdiagnostik in der Kita. Mercator-Institut für Sprachförderung und Deutsch als Zweitsprache.\nWilbert, J. (2011). Motivationale Faktoren in der Sonderpädagogik bei Lernstörungen. (Habilitationsschrift). Universität Oldenburg.\nWilbert, J. (2010). Förderung der Motivation bei Lernstörungen. Kohlhammer.\nWilbert, J. (2006). Die Etikettierung eines Verhaltens als Fehlerhaft: Eine empirische Untersuchung zur bewussten Gewahrwerdung eigener Verhaltensfehler. Pabst Science Publishers.\n\n\n\nSoftware\n\nWilbert, J. (2023). scplot: An R package for visualizing single-case data (0.3.0) [English]. University of Potsdam. https://CRAN.R-project.org/package=scplot\nWilbert, J., & Lüke, T. (2023). Scan: Single-Case Data Analyses for Single and Multiple Baseline Designs. (0.57.1). University of Potsdam. https://CRAN.R-project.org/package=scan\nWilbert, J. (2020). scaledic: An R package for adding scaling information to variables in data frames (0.1.8). University of Potsdam. https://github.com/jazznbass/scaledic/\nWilbert, J., & Lüke, T. (2019). Scan: Single-Case Data Analyses for Single and Multiple Baseline Designs. (0.40). University of Potsdam.\nWilbert, J. (2016). Scan: Single-Case Data Analyses for Single and Multiple Baseline Designs. (0.20). University of Potsdam."
  },
  {
    "objectID": "links.html",
    "href": "links.html",
    "title": "Links",
    "section": "",
    "text": "My homepage at the University of Potsdam\n\n\n\nResearch gate\n\n\n\nGithub\n\n\n\nEmpirische Sonderpädagogik (Journal Empirical Research in Special Education)\n\n\n\nORCID\n\n\n\nGoogle Scholar\n\n\n\nOFS - Open Science Framework\n\n\n\nMy personal Twitter account"
  },
  {
    "objectID": "rpackages.html",
    "href": "rpackages.html",
    "title": "R Packages",
    "section": "",
    "text": "scanscaledicscplotmcscanwmisc\n\n\n\nscan - Single-Case Data Analyses for Single and Multiple Baseline Designs\nThis package provides a collection of procedures for analyzing, visualizing, and managing single-case data. These include piecewise linear regression models, multilevel models, overlap indices (PND, PEM, PAND, PET, tauU, baseline corrected tau), and randomization tests. Data preparation functions support outlier detection, handling missing values, scaling, truncating, rank transformation, and smoothing. An exporting function helps to generate html and latex tables in a publication friendly style.\nMore details can be found at https://jazznbass.github.io/scan-Book/.\nState: Stable CRAN version and extended developmental version on github\ngithub: https://github.com/jazznbass/scan\nCRAN: https://CRAN.R-project.org/package=scan\nwebpage: https://jazznbass.github.io/scan/\n\n\n\n\nscaledic - A dictionary for scales\nscaledic is an R package for extending data frames and tibbles with several scale related attributes. It is designed to implement (psychometric) scale information to items of a data frame. These include values, labels, sub scales, weights etc.. A couple of functions help to organize, extract, replace and impute missing values, find typos, build scale scores etc.\nFor now, scaledic is already working and up to the task but still in an experimental stage where I might change the basic syntax.\nAlso documentation is poor. I am working on that.\nBasically, scaledic loads a dictionary file that contains all relevant information and applies these to a data frame. Here, every variable corresponding to the ones describes in the dictionary gets a new attribute dic which contains a list with all dictionary values for that variable.\nState: Working but still experimental\ngithub: https://github.com/jazznbass/scaledic\nwebpage: https://jazznbass.github.io/scaledic/\n\n\n\n\nscplot - Visualizing single-case data\nscplot is an extension to the scan package which provides powerful functions to generate single-case data plots. I try to keep the syntax simple and readable but nevertheless also allowing for sophisticated and complex depictions.\nThe generated plots are compatible to ggplot2.\nState: Stable CRAN version and extended developmental version on github\ngithub: https://github.com/jazznbass/scplot\nCRAN: https://CRAN.R-project.org/package=scplot\nwebpage: https://jazznbass.github.io/scplot/\n\n\n\n\nmcscan - Conduction Monte Carlo Single-Case Studies\nmcscan is another extension to the scan package which provides functions for designing, conducting, and visualizing the results of Monte-Carlo Single-Case studies.\nState: Experimental\ngithub: https://github.com/jazznbass/mcscan/\n\n\n\n\nwmisc - Wilbert’s miscellaneous functions\nThis R package comprises miscellaneous functions that I use to ease my work. It is developed to help people who work with my code.\nState: Experimental"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Private blog",
    "section": "",
    "text": "This blog is only for internal use (e.g. teaching or sending ideas to colleagues). Please do not reference or cite things I say here :-)\n\n\n\n\n\n\n\n\n\n\n\n\nA link function for logistic regressions\n\n\n\nregression\n\n\nstatistics\n\n\nlink\n\n\nlogistic\n\n\n\nA brief explanation of the link function in logistic regression.\n\n\n\nJürgen Wilbert\n\n\nJun 22, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nTreatment vs. effect contrasts\n\n\n\nregression\n\n\nstatistics\n\n\ncontrasts\n\n\n\nHere is a simple example to show the differences between treatment and effect contrasts.\n\n\n\nJürgen Wilbert\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nContrasts in single-cases\n\n\n\ncontrasts\n\n\nregression\n\n\nstatistics\n\n\n\nContrasts in regression modells\n\n\n\nJürgen Wilbert\n\n\nSep 27, 2022\n\n\n\n\n\n\n\n\n\n\n\n\neRm\n\n\n\nirt\n\n\nrasch\n\n\neRm\n\n\nstatistics\n\n\n\nAn overview of extended Rasch modelling in R with the eRm package.\n\n\n\nJürgen Wilbert\n\n\nMay 31, 2021\n\n\n\n\n\n\n\n\n\n\n\n\nCreate Rmarkdown webpage on gitHub\n\n\n\nRmarkdown\n\n\nGitHub\n\n\nRStudio\n\n\nWebpage\n\n\n\nShort description how to create an Rmarkdown webpage and publish it on gitHub\n\n\n\nJürgen Wilbert\n\n\nApr 19, 2021\n\n\n\n\n\n\n\n\n\n\n\n\nSetup a new github / Rstudio project\n\n\n\nGit\n\n\nGitHub\n\n\nRStudio\n\n\n\nSet up a git project in Rstudio and publish it to gitHub\n\n\n\nJürgen Wilbert\n\n\nMar 18, 2021\n\n\n\n\n\n\n\n\n\n\n\n\nMultivariate multilevel analyses\n\n\n\nStatistics\n\n\nR\n\n\nMultilevel\n\n\nBayesian\n\n\nnlme\n\n\nMCMCglmm\n\n\n\nA short description how to do Multivariate Multilevel Analyses in R with the nlme and MCMCglmm packages\n\n\n\nJürgen Wilbert\n\n\nMar 17, 2021\n\n\n\n\n\n\n\n\nNo matching items"
  }
]