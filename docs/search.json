[
  {
    "objectID": "posts/contrasts.html",
    "href": "posts/contrasts.html",
    "title": "Treatment vs.¬†effect contrasts",
    "section": "",
    "text": "Example dataset\nCreate a random dataset with criteria y, predictors x1, x2 and gender.\n\ny and gender are correlated\ny and x1 are correlated only if gender is 1\ny and x2 are correlated only if gender is 1\nx1 and x2 are correlated\nx1 and x2 have an interaction effect on y only if gender is 1\n\n\nset.seed(1234)\nn &lt;- 2000\ngender &lt;- rep(0:1, each = n/2)\ny &lt;- sample(0:10, n, replace = TRUE) + gender * sample(0:10, n, replace = TRUE)\nx1 &lt;- sample(0:10, n, replace = TRUE) + gender * y\nx2 &lt;- x1 + sample(0:10, n, replace = TRUE) + gender * y\ny &lt;- y + (x1 &gt; median(x1) & x2 &gt; median(x2) & gender == 1) * sample(0:10, n, replace = TRUE) * 2\n\ndat &lt;- data.frame(y = y, x1 = x1, x2 = x2, gender = gender)\n\n\n\nDescriptives\n\nwmisc::nice_corrmatrix(dat, type = \"html\", numbered_columns = FALSE)\n\n\nCorrelation matrix.\n\n\nVariable\nn\nM\nSD\ny\nx1\nx2\ngender\n\n\n\n\ny\n2000\n11.67\n9.83\n-\n\n\n\n\n\nx1\n2000\n10.09\n6.80\n.79***\n-\n\n\n\n\nx2\n2000\n20.30\n12.88\n.82***\n.95***\n-\n\n\n\ngender\n2000\n0.50\n0.50\n.68***\n.74***\n.79***\n-\n\n\n\nNote: \n\n\n\n\n\n\n\n\n\n ‚úùp &lt; .10; *p &lt; .05; **p &lt; .01; ***p &lt; .001\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nContrasts\nThe left part of the table is with gender as treatment contrast (0 vs.¬†1) and the right part with gender as effect contrast (-1 vs.¬†1)\n\n# Gender has values 0 vs. 1 (treatment contrast)\nfit1 &lt;- lm(y ~ gender * x1 * x2, data = dat)\n\n# Gender hast -1 vs. 1 (effect contrast)\ndat$gender &lt;- car::recode(dat$gender, \"0 = -1; 1 = 1\")\n\nfit2 &lt;- lm(y ~ gender * x1 * x2, data = dat)\n\nsjPlot::tab_model(fit1, fit2, show.se = TRUE, show.ci = FALSE, col.order = c(\"est\", \"se\", \"std.est\", \"p\"), digits = 4, dv.labels = c(\"Treatment contrast&lt;br&gt; for gender\", \"Effect contrast&lt;br&gt; for gender\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n¬†\nTreatment contrast\nfor gender\nEffect contrast\nfor gender\n\n\nPredictors\nEstimates\nstd. Error\np\nEstimates\nstd. Error\np\n\n\n(Intercept)\n5.2577\n0.6189\n&lt;0.001\n-4.6274\n0.6427\n&lt;0.001\n\n\ngender\n-19.7703\n1.2853\n&lt;0.001\n-9.8852\n0.6427\n&lt;0.001\n\n\nx1\n-0.0695\n0.1358\n0.609\n0.6640\n0.0851\n&lt;0.001\n\n\nx2\n-0.0270\n0.0795\n0.734\n0.4363\n0.0482\n&lt;0.001\n\n\ngender √ó x1\n1.4671\n0.1702\n&lt;0.001\n0.7335\n0.0851\n&lt;0.001\n\n\ngender √ó x2\n0.9267\n0.0963\n&lt;0.001\n0.4633\n0.0482\n&lt;0.001\n\n\nx1 √ó x2\n0.0056\n0.0116\n0.629\n-0.0124\n0.0059\n0.036\n\n\n(gender √ó x1) √ó x2\n-0.0360\n0.0118\n0.002\n-0.0180\n0.0059\n0.002\n\n\nObservations\n2000\n2000\n\n\nR2 / R2 adjusted\n0.738 / 0.737\n0.738 / 0.737\n\n\n\n\n\n\n\n\nThe intercept in model1 (treatment contrast) is the mean of y for gender 0\nThe intercept in model2 (effect contrast) is the mean of y for all data\nAll predictors in model1 without a gender term are effects for gender 0 while the interactions with a gender term are effects for gender 1\nAll predictors in model2 without a gender term are effects across gender while the interactions with a gender term are the effects of gender (subtracted for gender 0 and added for gender 1).\ngender has a significant effect on y in both models\nx1, x2 and x1*x2 only have a significant effect on y in model 2\nAll gender interactions are significant in both models where the effect sizes and the standard errors of model2 are half of the corresponding values in model1, so p is identical.\n\n\n\nFor those who love Anovas ;-)\n\nfit1  |&gt; car::Anova(type = \"III\") |&gt; wmisc::nice_table()\n\n\n\n\n\nSum Sq\nDf\nF value\nPr(&gt;F)\n\n\n\n\n(Intercept)\n1834.702440\n1\n72.1670347\n0.0000000\n\n\ngender\n6014.888596\n1\n236.5924110\n0.0000000\n\n\nx1\n6.660056\n1\n0.2619697\n0.6088269\n\n\nx2\n2.943411\n1\n0.1157775\n0.7336959\n\n\ngender:x1\n1889.686051\n1\n74.3297855\n0.0000000\n\n\ngender:x2\n2352.201418\n1\n92.5225789\n0.0000000\n\n\nx1:x2\n5.937356\n1\n0.2335427\n0.6289624\n\n\ngender:x1:x2\n235.982758\n1\n9.2822550\n0.0023442\n\n\nResiduals\n50642.613736\n1992\nNA\nNA\n\n\n\n\n\n\n\n\nfit2  |&gt; car::Anova(type = \"III\") |&gt; wmisc::nice_table()\n\n\n\n\n\nSum Sq\nDf\nF value\nPr(&gt;F)\n\n\n\n\n(Intercept)\n1318.0715\n1\n51.845636\n0.0000000\n\n\ngender\n6014.8886\n1\n236.592411\n0.0000000\n\n\nx1\n1548.5771\n1\n60.912449\n0.0000000\n\n\nx2\n2085.6571\n1\n82.038201\n0.0000000\n\n\ngender:x1\n1889.6861\n1\n74.329785\n0.0000000\n\n\ngender:x2\n2352.2014\n1\n92.522579\n0.0000000\n\n\nx1:x2\n112.2512\n1\n4.415342\n0.0357425\n\n\ngender:x1:x2\n235.9828\n1\n9.282255\n0.0023442\n\n\nResiduals\n50642.6137\n1992\nNA\nNA"
  },
  {
    "objectID": "posts/2021-04-19.html",
    "href": "posts/2021-04-19.html",
    "title": "Create Rmarkdown webpage on gitHub",
    "section": "",
    "text": "Create a new R Project:\nFile -&gt; New Project -&gt; New Directory -&gt; Simple Rmarkdown website\nOpen new project\nActivate ‚Äúgit‚Äù versioning for this project (tools -&gt; project Options -&gt; Git/SVN)\nEdit the YAML file _site.yml:\nadd the line: `output_dir: ‚Äúdocs‚Äù``\nBuild website: Build -&gt; Build all\nChange to Github Desktop\nAdd repository: File -&gt; Add local repository\nClick: Publish repository\nOpen Github in Webbrowser and login\nGo to the new published repository\nClick Settings\nGo to menu Pages or scroll to Github Pages\nAt the field ‚ÄúSource‚Äù select master\nChange select folder from \\(root) to \\docs\nclick save\nCopy / remember / open the link to the new webpage that opens up! 16 Change to webpage project at RStudio\nCommit and publish all files [tab] Git -&gt; Commit\nChange to the new webpage address you remembered/copied or opened! (probably wait 30 seconds and renew the page)\n\nThat‚Äôs it!"
  },
  {
    "objectID": "posts/eRm.html",
    "href": "posts/eRm.html",
    "title": "eRm",
    "section": "",
    "text": "Keywords: irt, Rasch, eRm"
  },
  {
    "objectID": "posts/eRm.html#extract",
    "href": "posts/eRm.html#extract",
    "title": "eRm",
    "section": "Extract",
    "text": "Extract\n\npp_a &lt;- person.parameter(fit_a)\npp_d &lt;- person.parameter(fit_d)\n\ndat$pp_d &lt;- coef(pp_d) # add person parameter to raw data frame\ndat$pp_a &lt;- coef(pp_a) # add person parameter to raw data frame\n\nCaution! Raw values of 0 and 15 (upper and lower limit) are between -Inf/+Inf and the upper/lower cut off and are estimated based on the distribution shape.\n\nplot(pp_d, main = \"Dekodierungsleistung\")\n\n\n\nplot(pp_a, main = \"Automatisierung\")\n\n\n\n\n\nplotPImap(fit_d)"
  },
  {
    "objectID": "posts/eRm.html#visual-inspection-of-item-discrimination",
    "href": "posts/eRm.html#visual-inspection-of-item-discrimination",
    "title": "eRm",
    "section": "Visual inspection of item discrimination",
    "text": "Visual inspection of item discrimination\n\nplotjointICC(fit_d, xlim = c(-5, 5))\n\n\n\nplotjointICC(fit_a, xlim = c(-5, 5))"
  },
  {
    "objectID": "posts/eRm.html#likelihood-ratio-tests",
    "href": "posts/eRm.html#likelihood-ratio-tests",
    "title": "eRm",
    "section": "Likelihood ratio tests",
    "text": "Likelihood ratio tests\nLRtests test for the estimation ‚Äústability‚Äù across several sub-samples of the data set.\nA median split allows for checking if the item-difficulty estimations are constant for the lower and upper part of the performance scale. This is similar to a test for homoscedasticity.\n\nlr_d &lt;- LRtest(fit_d, splitcr = \"median\")\nlr_a &lt;- LRtest(fit_a, splitcr = \"median\")\n\nlr_d\n\n\nAndersen LR-test: \nLR-value: 6.954 \nChi-square df: 14 \np-value:  0.936 \n\nlr_a\n\n\nAndersen LR-test: \nLR-value: 17.088 \nChi-square df: 14 \np-value:  0.252 \n\n\n\nplotGOF(lr_d, conf= list())\n\n\n\nplotGOF(lr_a, ctrline= list())"
  },
  {
    "objectID": "posts/eRm.html#item-in-fit-out-fit",
    "href": "posts/eRm.html#item-in-fit-out-fit",
    "title": "eRm",
    "section": "Item In-Fit / Out Fit",
    "text": "Item In-Fit / Out Fit\nItemFit interpretation:\n\nlarger 2.0: Distorts or degrades the measurementsystem\n1.5-2.0: Unproductive for construction of measurement, but not degrading\n0.5-1.5: Productive for measurement\n&lt;0.5: Lessproductive for measurement, but not degrading. May produce misleadingly good reliabilities and separations\n\n\nitemfit(pp_d)\n\n\nItemfit Statistics: \n               Chisq df p-value Outfit MSQ Infit MSQ Outfit t Infit t Discrim\nD_01_Als      60.546 44   0.049      1.345     1.212    1.276   1.287   0.360\nD_02_Jan      55.231 44   0.119      1.227     1.163    0.846   0.950   0.397\nD_03_und      26.844 44   0.981      0.597     0.731   -1.722  -1.791   0.713\nD_04_Michael  42.051 44   0.555      0.934     0.931   -0.171  -0.382   0.569\nD_05_zum      46.485 44   0.370      1.033     1.029    0.211   0.232   0.490\nD_06_Schulhof 43.466 44   0.494      0.966     0.988   -0.040  -0.021   0.527\nD_07_kommen   45.764 44   0.399      1.017     1.036    0.153   0.277   0.462\nD_08_stehen   38.572 44   0.703      0.857     0.932   -0.491  -0.375   0.558\nD_09_die      52.715 44   0.173      1.171     1.064    0.697   0.444   0.457\nD_10_meisten  36.926 44   0.766      0.821     0.907   -0.634  -0.515   0.571\nD_11_aus      33.483 44   0.876      0.744     0.815   -0.945  -1.106   0.637\nD_12_der      33.313 44   0.880      0.740     0.892   -0.947  -0.652   0.569\nD_13_Klasse   57.032 44   0.090      1.267     1.124    1.027   0.792   0.417\nD_14_schon    47.227 44   0.342      1.049     0.937    0.273  -0.344   0.560\nD_15_da       57.058 44   0.090      1.268     1.174    1.036   1.068   0.382\n\nitemfit(pp_a)\n\n\nItemfit Statistics: \n                Chisq df p-value Outfit MSQ Infit MSQ Outfit t Infit t Discrim\nA_01_Als       63.799 45   0.034      1.387     1.123    1.244   0.785   0.432\nA_02_Jan       44.536 45   0.491      0.968     1.006    0.018   0.090   0.544\nA_03_und       49.213 45   0.308      1.070     1.164    0.330   1.037   0.427\nA_04_Michael   35.200 45   0.853      0.765     0.889   -0.765  -0.672   0.601\nA_05_zum       62.154 45   0.046      1.351     1.290    1.163   1.735   0.334\nA_06_Schulhof  40.073 45   0.680      0.871     1.017   -0.354   0.157   0.534\nA_07_kommen    22.361 45   0.998      0.486     0.640   -2.086  -2.575   0.783\nA_08_stehen    28.876 45   0.970      0.628     0.823   -1.268  -1.104   0.655\nA_09_die       41.513 45   0.620      0.902     0.878   -0.245  -0.759   0.625\nA_10_meisten   40.687 45   0.655      0.885     0.899   -0.278  -0.584   0.589\nA_11_aus       34.902 45   0.861      0.759     0.929   -0.772  -0.395   0.591\nA_12_der       39.471 45   0.705      0.858     0.891   -0.347  -0.621   0.582\nA_13_Klasse    33.062 45   0.906      0.719     0.884   -0.933  -0.693   0.610\nA_14_schon     51.039 45   0.248      1.110     1.110    0.456   0.718   0.470\nA_15_da       103.787 45   0.000      2.256     1.387    3.192   2.191   0.239"
  },
  {
    "objectID": "posts/eRm.html#person-in-fit-out-fit",
    "href": "posts/eRm.html#person-in-fit-out-fit",
    "title": "eRm",
    "section": "Person In-Fit / Out Fit",
    "text": "Person In-Fit / Out Fit\nPersonfit interpretation:\n\nlarger 2.0: Distorts or degrades the measurementsystem\n1.5-2.0: Unproductive for construction of measurement, but not degrading\n0.5-1.5: Productive for measurement\n&lt;0.5: Lessproductive for measurement, but not degrading. May produce misleadingly good reliabilities and separations\n\n\npersonfit(pp_d)\n\n\nPersonfit Statistics: \n     Chisq df p-value Outfit MSQ Infit MSQ Outfit t Infit t\nP3  18.927 14   0.168      1.262     1.049     0.61    0.27\nP5  15.238 14   0.362      1.016     1.015     0.22    0.21\nP6  14.437 14   0.418      0.962     1.000     0.27    0.30\nP7  13.111 14   0.518      0.874     0.945    -0.19   -0.02\nP8  15.300 14   0.358      1.020     1.012     0.17    0.13\nP9  13.724 14   0.470      0.915     0.982     0.04    0.15\nP10 14.481 14   0.415      0.965     0.991    -0.03    0.06\nP11 17.025 14   0.255      1.135     1.058     0.55    0.30\nP12 15.999 14   0.313      1.067     1.043     0.39    0.29\nP13 18.603 14   0.181      1.240     1.098     0.69    0.37\nP14 14.437 14   0.418      0.962     1.000     0.27    0.30\nP15 13.724 14   0.470      0.915     0.982     0.04    0.15\nP16 15.778 14   0.327      1.052     1.035     0.27    0.22\nP17 13.620 14   0.478      0.908     0.960    -0.10    0.02\nP18 15.606 14   0.338      1.040     1.041     0.59    0.59\nP19 13.829 14   0.463      0.922     0.957    -0.18   -0.07\nP20 15.778 14   0.327      1.052     1.035     0.27    0.22\nP21 13.658 14   0.475      0.911     0.936    -0.40   -0.29\nP22 13.922 14   0.456      0.928     0.926    -1.01   -1.05\nP23 13.165 14   0.514      0.878     0.880    -1.77   -1.76\nP24 13.396 14   0.496      0.893     0.919    -0.49   -0.39\nP25 14.991 14   0.379      0.999     1.000     0.02    0.03\nP26 13.170 14   0.513      0.878     0.880    -1.77   -1.76\nP27 15.468 14   0.347      1.031     1.021     0.29    0.22\nP28 16.349 14   0.293      1.090     1.067     0.74    0.60\nP29 14.214 14   0.434      0.948     0.953    -0.72   -0.68\nP30 16.024 14   0.312      1.068     1.063     0.95    0.93\nP31 15.018 14   0.377      1.001     1.007     0.07    0.10\nP32 14.503 14   0.413      0.967     0.975    -0.02    0.00\nP33 14.440 14   0.417      0.963     0.968    -0.26   -0.23\nP34 17.361 14   0.237      1.157     1.109     0.62    0.47\nP35 14.218 14   0.434      0.948     0.955    -0.20   -0.18\nP36 14.667 14   0.401      0.978     0.973     0.08    0.06\nP37 13.428 14   0.493      0.895     0.966     0.00    0.12\nP38 15.561 14   0.341      1.037     1.014     0.25    0.14\nP39 14.890 14   0.386      0.993     0.985     0.03   -0.02\nP40 17.319 14   0.240      1.155     1.049     0.45    0.27\nP41 16.305 14   0.295      1.087     1.036     0.34    0.25\nP42 14.612 14   0.405      0.974     1.005     0.28    0.30\nP43  9.352 14   0.808      0.623     0.923    -0.16    0.21\nP44 15.099 14   0.371      1.007     1.021     0.15    0.18\nP45 15.065 14   0.374      1.004     1.005     0.09    0.09\nP46 16.332 14   0.294      1.089     1.020     0.40    0.32\nP47 16.305 14   0.295      1.087     1.036     0.34    0.25\nP48 18.262 14   0.195      1.217     1.034     0.53    0.34\n\npersonfit(pp_a)\n\n\nPersonfit Statistics: \n     Chisq df p-value Outfit MSQ Infit MSQ Outfit t Infit t\nP4  12.220 14   0.589      0.815     0.980     0.11    0.27\nP5   8.725 14   0.848      0.582     0.911    -0.21    0.19\nP6  14.450 14   0.417      0.963     1.011     0.14    0.20\nP7  16.258 14   0.298      1.084     0.981     0.34    0.15\nP8  13.671 14   0.475      0.911     0.999     0.22    0.30\nP9  13.088 14   0.520      0.873     0.937    -0.34   -0.15\nP10  8.725 14   0.848      0.582     0.911    -0.21    0.19\nP11 14.977 14   0.380      0.998     0.996     0.01   -0.02\nP12 14.291 14   0.428      0.953     1.000     0.02    0.13\nP13 16.408 14   0.289      1.094     1.082     0.50    0.48\nP14 16.279 14   0.297      1.085     1.040     0.34    0.26\nP15 12.310 14   0.581      0.821     0.957    -0.12    0.10\nP16 19.363 14   0.152      1.291     1.057     0.65    0.29\nP17 18.928 14   0.168      1.262     1.122     0.72    0.43\nP18 12.792 14   0.543      0.853     0.867    -1.06   -1.04\nP19 15.592 14   0.339      1.039     1.022     0.26    0.22\nP20 14.411 14   0.420      0.961     0.988    -0.12    0.00\nP21 12.136 14   0.595      0.809     0.814    -2.18   -2.21\nP22 14.732 14   0.397      0.982     0.980    -0.16   -0.20\nP23 13.039 14   0.523      0.869     0.884    -0.93   -0.89\nP24 14.846 14   0.389      0.990     0.995    -0.08   -0.02\nP25 13.750 14   0.468      0.917     0.909    -0.90   -1.02\nP26 16.428 14   0.288      1.095     1.096     1.03    1.08\nP27 13.448 14   0.492      0.897     0.899    -1.13   -1.16\nP28 15.995 14   0.314      1.066     1.070     0.38    0.42\nP29 13.976 14   0.451      0.932     0.940    -0.45   -0.43\nP30 16.719 14   0.271      1.115     1.111     1.22    1.25\nP31 17.110 14   0.250      1.141     1.117     1.01    0.90\nP32 16.487 14   0.285      1.099     1.094     1.07    1.07\nP33 12.345 14   0.579      0.823     0.845    -0.83   -0.78\nP34 13.757 14   0.468      0.917     0.921    -0.56   -0.58\nP35 17.053 14   0.253      1.137     1.119     0.99    0.92\nP36 15.893 14   0.320      1.060     1.063     0.66    0.73\nP37 15.219 14   0.363      1.015     1.031     0.15    0.20\nP38 14.328 14   0.426      0.955     1.007     0.27    0.30\nP39 15.560 14   0.341      1.037     1.048     0.22    0.26\nP40 15.269 14   0.360      1.018     1.014     0.15    0.14\nP41 14.119 14   0.441      0.941     0.951    -0.10   -0.09\nP42 13.641 14   0.477      0.909     0.965    -0.09    0.04\nP43 17.825 14   0.215      1.188     1.071     0.50    0.31\nP44 12.803 14   0.542      0.854     0.989     0.15    0.28\nP45 20.151 14   0.125      1.343     1.050     0.64    0.35\nP46 20.151 14   0.125      1.343     1.050     0.64    0.35\nP47 11.101 14   0.678      0.740     0.910    -0.29    0.02\nP48 20.151 14   0.125      1.343     1.050     0.64    0.35\nP49 20.152 14   0.125      1.343     1.050     0.64    0.35"
  },
  {
    "objectID": "posts/multivariate_multilevel.html",
    "href": "posts/multivariate_multilevel.html",
    "title": "Multivariate multilevel analyses",
    "section": "",
    "text": "Most of our data have a multilevel structure. But ‚Äústandard‚Äù Manova analyzes do not take a nested structure with various strata into account. What we need is a multivariate extension of the univariate multilevel regression approach.\nMultivariate multilevel analyses has various subtypes depending on the assumptions of the intercorrelations and variance of the dependent variables (dvs).\nIn this paper by Ben Bolker (https://rpubs.com/bbolker/3336), five subtypes are described. Interestingly, the case #1 assumes equal variance of all dvs and equal (positive ?) correlations among the dvs. In this case, is is very easy: A random slope model with the dvs turned into a new random slope categorical variable.\nWhen dvs have different variances, the models must be weighted by their variance and when the intercorrelation between the dvs varies, the intercorrelations of the residuals have to be fixed to take these variations into account.\nOne approach is a Bayesian analyses with a Markov-Chain Monte-Carlo method. There is a vignette of the MCMCglmm package that explains how to do these analyses more in detail (&lt;https://cran.r-project.org/web/packages/MCMCglmm/vignettes/CourseNotes.pdf&gt;). Note: This example is for repeated measures."
  },
  {
    "objectID": "posts/multivariate_multilevel.html#a-computational-example",
    "href": "posts/multivariate_multilevel.html#a-computational-example",
    "title": "Multivariate multilevel analyses",
    "section": "A computational example",
    "text": "A computational example\nFirst we need an example dataset to work with. I want two criteria (av1 and av2) and one explanatory variable (dv1) nested within four groups\n\nset.seed(1234)\nncases &lt;- 800\nngroups &lt;- 4\ndat &lt;- list()\ndat$id &lt;- 1:ncases\ndat$group &lt;- rep_len(1:ngroups, ncases)\ndat$av1 &lt;- rnorm(ncases, 50, 10)\ndat$av2 &lt;- (dat$av1 + rnorm(ncases, 50, 10)) / 2\ndat$dv1 &lt;- (dat$av1 + dat$av2 + rnorm(ncases, 50, 10)) /3\ndat$av1 &lt;- dat$av1 + (dat$group / ngroups * 10)\ndat$av2 &lt;- dat$av2 + (dat$group / ngroups * 10)\ndat$dv1 &lt;- dat$dv1 + (dat$group / ngroups * 10)\ndat$dv1 &lt;- scale(dat$dv1, scale = FALSE)\n#dat$id &lt;- rep(1:ncases, ngroups)\n#dat$obs &lt;- 1:(ncases*ngroups)\ndat &lt;- as.data.frame(dat)\n\ndat2 &lt;- dat %&gt;%\n  pivot_longer(cols = c(\"av1\", \"av2\"), names_to = \"trait\") %&gt;%\n  mutate(trait = as.factor(trait))"
  },
  {
    "objectID": "posts/multivariate_multilevel.html#manova-without-nesting-data-structure",
    "href": "posts/multivariate_multilevel.html#manova-without-nesting-data-structure",
    "title": "Multivariate multilevel analyses",
    "section": "Manova without nesting data structure",
    "text": "Manova without nesting data structure\nThe simple Manova has some disadvantages here:\n\nNo nested data structure\nAssumes all variances are equal (also: across all strata, which it does not take into account anyway).\nAssumes all intercorrelations of the variables are equal (again also across all strata)\n\n\nmodel &lt;- lm(cbind(av1+av2) ~ 1 + dv1, data = dat)\nsummary(model)\n\n\nCall:\nlm(formula = cbind(av1 + av2) ~ 1 + dv1, data = dat)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-30.0270  -5.3806   0.1014   5.6296  24.7045 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 112.1179     0.3033  369.69   &lt;2e-16 ***\ndv1           2.0226     0.0430   47.04   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.578 on 798 degrees of freedom\nMultiple R-squared:  0.735, Adjusted R-squared:  0.7346 \nF-statistic:  2213 on 1 and 798 DF,  p-value: &lt; 2.2e-16\n\ncar::Anova(model, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: cbind(av1 + av2)\n              Sum Sq  Df  F value    Pr(&gt;F)    \n(Intercept) 10056336   1 136672.2 &lt; 2.2e-16 ***\ndv1           162828   1   2212.9 &lt; 2.2e-16 ***\nResiduals      58717 798                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "posts/multivariate_multilevel.html#multilevel-regression-approach",
    "href": "posts/multivariate_multilevel.html#multilevel-regression-approach",
    "title": "Multivariate multilevel analyses",
    "section": "Multilevel regression approach",
    "text": "Multilevel regression approach\nThe following analyses follow the example of Snijders and Bosker (2012, Chapter 16).\nNote: Dropping the intercept will set the main effect predictors of the dummy variable to the mean of the first variable. Also, dropping the main effect of the variable for the interaction will have an analogues effect for the interactions: the interaction with the first variable is displayed (otherwise, the main effect would entail the interaction of the first - here dummy - category and the variable).\n\n\nmodel_1 &lt;- lme(value ~ 0 + trait + dv1:trait, random = ~ 0 + trait |group,\ndata = dat2)\nsummary(model_1)\n\nLinear mixed-effects model fit by REML\n  Data: dat2 \n       AIC      BIC    logLik\n  9937.194 9980.196 -4960.597\n\nRandom effects:\n Formula: ~0 + trait | group\n Structure: General positive-definite, Log-Cholesky parametrization\n         StdDev    Corr  \ntraitav1 1.2311183 tratv1\ntraitav2 0.5143689 -0.816\nResidual 5.3422224       \n\nFixed effects:  value ~ 0 + trait + dv1:trait \n                Value Std.Error   DF   t-value p-value\ntraitav1     55.97952 0.6438845 1593  86.94032       0\ntraitav2     56.13836 0.3190894 1593 175.93303       0\ntraitav1:dv1  1.24563 0.0292196 1593  42.62999       0\ntraitav2:dv1  0.81402 0.0279074 1593  29.16883       0\n Correlation: \n             tratv1 tratv2 trt1:1\ntraitav2     -0.628              \ntraitav1:dv1  0.000  0.000       \ntraitav2:dv1  0.000  0.000 -0.038\n\nStandardized Within-Group Residuals:\n        Min          Q1         Med          Q3         Max \n-4.69589000 -0.66817031  0.02572767  0.63497999  3.13414812 \n\nNumber of Observations: 1600\nNumber of Groups: 4 \n\n\n\n#with weighted variances\nmodel_1b &lt;- update(model_1,  weights=varIdent(form=~1|trait))\nsummary(model_1b)\n\nLinear mixed-effects model fit by REML\n  Data: dat2 \n       AIC      BIC    logLik\n  9870.822 9919.199 -4926.411\n\nRandom effects:\n Formula: ~0 + trait | group\n Structure: General positive-definite, Log-Cholesky parametrization\n         StdDev    Corr  \ntraitav1 1.2103832 tratv1\ntraitav2 0.5547227 -0.774\nResidual 6.0607475       \n\nVariance function:\n Structure: Different standard deviations per stratum\n Formula: ~1 | trait \n Parameter estimates:\n      av1       av2 \n1.0000000 0.7442685 \nFixed effects:  value ~ 0 + trait + dv1:trait \n                Value Std.Error   DF   t-value p-value\ntraitav1     55.97952 0.6420068 1593  87.19460       0\ntraitav2     56.13836 0.3199433 1593 175.46347       0\ntraitav1:dv1  1.24415 0.0329916 1593  37.71123       0\ntraitav2:dv1  0.81271 0.0239648 1593  33.91260       0\n Correlation: \n             tratv1 tratv2 trt1:1\ntraitav2     -0.632              \ntraitav1:dv1  0.000  0.000       \ntraitav2:dv1  0.000  0.000 -0.037\n\nStandardized Within-Group Residuals:\n        Min          Q1         Med          Q3         Max \n-4.13902014 -0.69797783  0.02637369  0.64981098  2.76937510 \n\nNumber of Observations: 1600\nNumber of Groups: 4 \n\n\n\n#correlation between dvs\nmodel_1c &lt;- update(model_1b, corr = corSymm(form = ~ as.numeric(trait)|group/id))\n\nsummary(model_1c)\n\nLinear mixed-effects model fit by REML\n  Data: dat2 \n       AIC      BIC    logLik\n  9800.954 9854.707 -4890.477\n\nRandom effects:\n Formula: ~0 + trait | group\n Structure: General positive-definite, Log-Cholesky parametrization\n         StdDev    Corr  \ntraitav1 1.2152290 tratv1\ntraitav2 0.5592672 -0.832\nResidual 6.0605912       \n\nCorrelation Structure: General\n Formula: ~as.numeric(trait) | group/id \n Parameter estimate(s):\n Correlation: \n  1    \n2 0.294\nVariance function:\n Structure: Different standard deviations per stratum\n Formula: ~1 | trait \n Parameter estimates:\n      av1       av2 \n1.0000000 0.7442721 \nFixed effects:  value ~ 0 + trait + dv1:trait \n                Value Std.Error   DF   t-value p-value\ntraitav1     55.97952 0.6442894 1593  86.88568       0\ntraitav2     56.13836 0.3219135 1593 174.38959       0\ntraitav1:dv1  1.24557 0.0325430 1593  38.27480       0\ntraitav2:dv1  0.81125 0.0236929 1593  34.24036       0\n Correlation: \n             tratv1 tratv2 trt1:1\ntraitav2     -0.633              \ntraitav1:dv1  0.000  0.000       \ntraitav2:dv1  0.000  0.000  0.243\n\nStandardized Within-Group Residuals:\n        Min          Q1         Med          Q3         Max \n-4.14677763 -0.70322170  0.02487244  0.65471196  2.78718461 \n\nNumber of Observations: 1600\nNumber of Groups: 4 \n\n#sjPlot::tab_model(model_1)\n\n\n# lme(value ~ 0 + trait + dv1:trait, \n#     random = ~ 0 + trait |group, \n#     weights = varIdent(form = ~ 1|trait), \n#     corr = corSymm(form = ~ as.numeric(trait)|group/id), \n#     data = dat2\n# )\n\nVariation of this model:\nBy standardizing the dependent variable before calculating the models (`value &lt;- scale(value)`), the main effects depict the standardized deviation from the overall mean of both variables and following that, the statistical test (se,t,p) represent the deviation of the mean of a variable from the overall mean."
  },
  {
    "objectID": "posts/multivariate_multilevel.html#mcmcglmm-solution-most-accurate",
    "href": "posts/multivariate_multilevel.html#mcmcglmm-solution-most-accurate",
    "title": "Multivariate multilevel analyses",
    "section": "MCMCglmm solution (most accurate)",
    "text": "MCMCglmm solution (most accurate)\nThe Bayesian solution by means of Markov-Chain Monte-Carlo glmm is able to take variable variances (random slopes) and variable intercorrelations of the dvs into account.\nThe model sometimes fails, asking for a better prior. Usually a rerun will fit the model (as the priors are set randomly as an iteration starting point). Here I chose a seed to make it work.\n\nlibrary(MCMCglmm)\n\nLoading required package: Matrix\n\n\n\nAttaching package: 'Matrix'\n\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\n\nLoading required package: coda\n\n\nLoading required package: ape\n\nset.seed(12322)\nmodel_2 &lt;- MCMCglmm(cbind(av1, av2) ~ 0 + trait + dv1:trait, random = ~us(trait):id, rcov = ~us(trait):units, data = dat, family = c(\"gaussian\", \"gaussian\"), verbose = FALSE)\nsummary(model_2)\n\n\n Iterations = 3001:12991\n Thinning interval  = 10\n Sample size  = 1000 \n\n DIC: -506.2845 \n\n G-structure:  ~us(trait):id\n\n                     post.mean l-95% CI u-95% CI eff.samp\ntraitav1:traitav1.id   31.9930  29.2626  35.3370  454.946\ntraitav2:traitav1.id   -3.1208  -3.6026  -2.7050    7.048\ntraitav1:traitav2.id   -3.1208  -3.6026  -2.7050    7.048\ntraitav2:traitav2.id    0.3063   0.2519   0.4008    3.961\n\n R-structure:  ~us(trait):units\n\n                        post.mean l-95% CI u-95% CI eff.samp\ntraitav1:traitav1.units     6.987    5.949    8.063    44.63\ntraitav2:traitav1.units    11.830   10.412   13.137    96.42\ntraitav1:traitav2.units    11.830   10.412   13.137    96.42\ntraitav2:traitav2.units    20.101   18.247   22.101   900.90\n\n Location effects: cbind(av1, av2) ~ 0 + trait + dv1:trait \n\n             post.mean l-95% CI u-95% CI eff.samp  pMCMC    \ntraitav1       55.9822  55.4701  56.4032   1160.2 &lt;0.001 ***\ntraitav2       56.1362  55.8311  56.4564   1000.0 &lt;0.001 ***\ntraitav1:dv1    1.1856   1.1252   1.2410   1113.3 &lt;0.001 ***\ntraitav2:dv1    0.8372   0.7932   0.8817    975.2 &lt;0.001 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "posts/multivariate_multilevel.html#repeated-measurements",
    "href": "posts/multivariate_multilevel.html#repeated-measurements",
    "title": "Multivariate multilevel analyses",
    "section": "Repeated measurements",
    "text": "Repeated measurements"
  },
  {
    "objectID": "posts/git-github/index.html",
    "href": "posts/git-github/index.html",
    "title": "Setup a new github / Rstudio project",
    "section": "",
    "text": "Start a new RStudio Project\nTools ‚Äì&gt; Project Options ‚Äì&gt; Git/SVN: Set Version Control System to Git\nCommit a first file\nChange to Github Desktop\nFile ‚Äì&gt; Add local repository: Add the new project folder\nOn the main screen click: Add/push repository to git (or similar)\nGive the repository a name: et voil√†!\n\nOptional:\nChange to Rstudio\nPull and Push committed files"
  },
  {
    "objectID": "posts/2023-06-21/index.html",
    "href": "posts/2023-06-21/index.html",
    "title": "Logits as a link function in logistic regressions",
    "section": "",
    "text": "If you estimate a dichotomous outcome variable \\(y\\) (\\(y\\) can take the values 0 or 1) with a standard ols (ordinary least squares) regression the distribution of \\(y\\) does not meet ols regression assumptions. Specifically, predicted values can be outside \\(\\{0, 1\\}\\) and are not continuous and normal distributed. A common solution for this problem is to apply a generalization of the linear regression model which is (surprise, surprise) called the generalized linear model (GLM). One aspect of the generalized linear model is that the linear combination of the predictors (linear because we assume that the added up predictors are interval scaled) are linked to the distribution of the outcome variable via a function which is called: the link function (uhhh).\nIt is helpful to keep in mind that for dichotomous variables, we estimate/predict the probabilities that \\(y=1\\). That is, the predicted values are probabilities of \\([0, 1]\\) (a continuous interval between 0 and 1) and not \\(\\{0, 1\\}\\) (either 0 or 1). Therefore, we are looking for a link function that turns the linear combined predictors into a probability estimation. In case of a logistic regression, we need a formula, that turns continuous values from \\([-\\infty, +\\infty]\\) to a probability (where \\(0\\) corresponds to a 50% probability) and vise-versa, a probability into a continuous scale with values from \\([-\\infty, +\\infty]\\). This transformation is called a logit transformation and the distribution of the transformed predicted \\(y\\) values is a logistic distribution. This kind of function (i.e.¬†a function that links the distribution of linear combinations of the predictors to the distribution of the criteria in a regression) is called a link function."
  },
  {
    "objectID": "posts/2023-06-21/index.html#problem-and-solution",
    "href": "posts/2023-06-21/index.html#problem-and-solution",
    "title": "Logits as a link function in logistic regressions",
    "section": "",
    "text": "If you estimate a dichotomous outcome variable \\(y\\) (\\(y\\) can take the values 0 or 1) with a standard ols (ordinary least squares) regression the distribution of \\(y\\) does not meet ols regression assumptions. Specifically, predicted values can be outside \\(\\{0, 1\\}\\) and are not continuous and normal distributed. A common solution for this problem is to apply a generalization of the linear regression model which is (surprise, surprise) called the generalized linear model (GLM). One aspect of the generalized linear model is that the linear combination of the predictors (linear because we assume that the added up predictors are interval scaled) are linked to the distribution of the outcome variable via a function which is called: the link function (uhhh).\nIt is helpful to keep in mind that for dichotomous variables, we estimate/predict the probabilities that \\(y=1\\). That is, the predicted values are probabilities of \\([0, 1]\\) (a continuous interval between 0 and 1) and not \\(\\{0, 1\\}\\) (either 0 or 1). Therefore, we are looking for a link function that turns the linear combined predictors into a probability estimation. In case of a logistic regression, we need a formula, that turns continuous values from \\([-\\infty, +\\infty]\\) to a probability (where \\(0\\) corresponds to a 50% probability) and vise-versa, a probability into a continuous scale with values from \\([-\\infty, +\\infty]\\). This transformation is called a logit transformation and the distribution of the transformed predicted \\(y\\) values is a logistic distribution. This kind of function (i.e.¬†a function that links the distribution of linear combinations of the predictors to the distribution of the criteria in a regression) is called a link function."
  },
  {
    "objectID": "posts/2023-06-21/index.html#the-logit-transformation",
    "href": "posts/2023-06-21/index.html#the-logit-transformation",
    "title": "Logits as a link function in logistic regressions",
    "section": "The logit transformation",
    "text": "The logit transformation\nThe formula to turn probabilities into continuous values (here logits) is:\n\\[logit(y_i)=log(\\frac{P(y_i=1)}{1-P(y_i=0)})=log(odds)\\]\nHere is the function plot for illustration with probabilities on x and logits on y:\n\n\nCode\n# identical: plot(function(x) qlogis(x))\nplot(function(x) log(x/(1-x)))\n\n\n\n\n\nLogit/logistic function\n\n\n\n\nThe formula to turn continuous values (here logits) into probabilities is:\n\\[P(y_i=1)=\\frac{exp(x)}{1 + exp(x)}\\]\nHere is the function plot for illustration with logits on x and probablities on y:\n\n\nCode\n# identica: plot(function(x) plogis(x), -6,6)\nplot(function(x) exp(x)/(1 + exp(x)), from = -6, to = 6)\n\n\n\n\n\nDistribution of the logistic function (invers logistic)"
  },
  {
    "objectID": "posts/2023-06-21/index.html#what-are-logits",
    "href": "posts/2023-06-21/index.html#what-are-logits",
    "title": "Logits as a link function in logistic regressions",
    "section": "What are logits?",
    "text": "What are logits?\nLogits are the logarithm of the odds of a probability \\(log(Odds)\\). Odds is a way to represent the probability of an event: If the odds are four against one (\\(4\\over1\\)), than out of 5 events, 4 have one category of outcome and 1 has an opposite outcome (for example, if a horse runs five races and we expect that it will win four races and loose one, the odds are \\(4\\over1\\)). If the odds are &lt; 1, the probability of an event is below 50%. For example, if the odds are 0.25 = \\(\\frac{1}{4}\\) we expect that the horse will win one out of five races.\n\n\n\n\n\n\nCaution\n\n\n\nCaution: Probabilities and odds can be confused easily but are not identical. A probability of \\(1\\over4\\) would index that a specific outcome happens in 1 out of 4 events, whereas odds of \\(1\\over4\\) would index that an event has the probability for two possible outcomes of 1 against 4. For this example, odds of \\(1\\over4\\) equals a probability of \\(1\\over5\\) equals \\(0.20\\).\n\n\nThe odds are calculated as:\n\\[Odds(y_i)=\\frac{P(y_i=1)}{1-P(y_i=0)}\\]\nFor example, if we have a probability of 25%, the odds are:\n\\[Odds=\\frac{0.25}{0.75}={1\\over3}\\]\nThe formula for calculating logits is:\n\\[logit(y_i)=log(\\frac{P(y_i=1)}{1-P(y_i=0)})=log(odds)\\]\nFor example, if we have a 25% probability that is:\n\\[logit(P=0.25)=log(\\frac{0.25}{0.75})=log({1\\over3})=-1.098612\\]"
  },
  {
    "objectID": "posts/2023-06-21/index.html#example",
    "href": "posts/2023-06-21/index.html#example",
    "title": "Logits as a link function in logistic regressions",
    "section": "Example",
    "text": "Example\nTo be continued üòâ"
  },
  {
    "objectID": "posts/contrasts/index.html",
    "href": "posts/contrasts/index.html",
    "title": "Contrasts in single-cases",
    "section": "",
    "text": "plottable\n\n\n\n\n\n\n\n\n\n\n\n\nSingle case data frame with 1 cases\n\n\n\n\n\n\n\n\nPawel\n\n\n\nvalues\nmt\nphase\n\n\n\n\n10\n1\nA1\n\n\n19\n2\nA1\n\n\n11\n3\nA1\n\n\n6\n4\nA1\n\n\n16\n5\nA1\n\n\n16\n6\nA1\n\n\n17\n7\nA1\n\n\n18\n8\nA1\n\n\n12\n9\nA1\n\n\n12\n10\nA1\n\n\n39\n11\nB1\n\n\n18\n12\nB1\n\n\n25\n13\nB1\n\n\n31\n14\nB1\n\n\n29\n15\nB1\n\n\n24\n16\nB1\n\n\n37\n17\nB1\n\n\n17\n18\nB1\n\n\n21\n19\nB1\n\n\n18\n20\nB1\n\n\n16\n21\nA2\n\n\n17\n22\nA2\n\n\n19\n23\nA2\n\n\n21\n24\nA2\n\n\n10\n25\nA2\n\n\n11\n26\nA2\n\n\n23\n27\nA2\n\n\n11\n28\nA2\n\n\n10\n29\nA2\n\n\n9\n30\nA2\n\n\n34\n31\nB2\n\n\n35\n32\nB2\n\n\n28\n33\nB2\n\n\n30\n34\nB2\n\n\n22\n35\nB2\n\n\n21\n36\nB2\n\n\n21\n37\nB2\n\n\n22\n38\nB2\n\n\n23\n39\nB2\n\n\n34\n40\nB2\n\n\n\n\n\n\n\n\n\n\n\n# dataset:\ndf &lt;- as.data.frame(exampleA1B1A2B2$Pawel)\ndf$mt &lt;- df$mt - df$mt[1]\n\n# mean of all phases\n\n(means &lt;- tapply(df$values, df$phase, mean))\n  A1   B1   A2   B2 \n13.7 25.9 14.7 27.0 \n(grand_mean &lt;- mean(means))\n[1] 20.325\n\n\n# Plm function reference:\nplm(exampleA1B1A2B2$Pawel, contrast = \"first\", trend = FALSE, slope = FALSE) %&gt;% coef() %&gt;% .[,1]\n\n(Intercept)     phaseB1     phaseA2     phaseB2 \n       13.7        12.2         1.0        13.3 \n\nplm(exampleA1B1A2B2$Pawel, contrast = \"preceding\", trend = FALSE, slope = FALSE) %&gt;% coef() %&gt;% .[,1]\n\n(Intercept)     phaseB1     phaseA2     phaseB2 \n       13.7        12.2       -11.2        12.3"
  },
  {
    "objectID": "posts/contrasts/index.html#treatment-contrast",
    "href": "posts/contrasts/index.html#treatment-contrast",
    "title": "Contrasts in single-cases",
    "section": "Treatment contrast",
    "text": "Treatment contrast\nCompare mean of second to last phase against first phase (intercept)\nThe Intercept is the mean of a reference phase (defaults to the first).\nThe predictors are the differences from a phase to the reference (intercept).\n\ntreatment &lt;- contr.treatment(4)\ncolnames(treatment) &lt;- c(\"B1vsA1\",\"A2vsA1\",\"B2vsA1\")\ntreatment\n\n  B1vsA1 A2vsA1 B2vsA1\n1      0      0      0\n2      1      0      0\n3      0      1      0\n4      0      0      1\n\nlm(values~phase, data=df, contrasts = list(phase = treatment)) |&gt; coef()\n\n(Intercept) phaseB1vsA1 phaseA2vsA1 phaseB2vsA1 \n       13.7        12.2         1.0        13.3 \n\nc(Intercept = 13.7, # phaseA1\n  phaseB1vsA1 = 25.9 - 13.7, \n  phaseA2vsA1 = 14.7 - 13.7,\n  phaseB2vsA1 = 27 - 13.7)\n\n  Intercept phaseB1vsA1 phaseA2vsA1 phaseB2vsA1 \n       13.7        12.2         1.0        13.3"
  },
  {
    "objectID": "posts/contrasts/index.html#sum-contrast",
    "href": "posts/contrasts/index.html#sum-contrast",
    "title": "Contrasts in single-cases",
    "section": "Sum contrast",
    "text": "Sum contrast\nComparison from the first to the second last phase with the overall mean (Intercept is overall mean)\nThe Intercept is the overall mean.\nThe predictors are the differences from a phase mean to the overall mean.\n\nsum &lt;- contr.sum(4)\ncolnames(sum) &lt;- c(\"A1vsMean\",\"B1vsMean\",\"A2vsMean\")\nsum\n\n  A1vsMean B1vsMean A2vsMean\n1        1        0        0\n2        0        1        0\n3        0        0        1\n4       -1       -1       -1\n\nlm(values~phase, data=df, contrasts = list(phase = sum)) |&gt; coef()\n\n  (Intercept) phaseA1vsMean phaseB1vsMean phaseA2vsMean \n       20.325        -6.625         5.575        -5.625 \n\nc(Intercept = grand_mean,\n  phaseA1vsMean = 13.7 - grand_mean, \n  phaseB1vsMean = 25.9 - grand_mean, \n  phaseA2vsMean = 14.7 - grand_mean)\n\n    Intercept phaseA1vsMean phaseB1vsMean phaseA2vsMean \n       20.325        -6.625         5.575        -5.625"
  },
  {
    "objectID": "posts/contrasts/index.html#helmert-contrast",
    "href": "posts/contrasts/index.html#helmert-contrast",
    "title": "Contrasts in single-cases",
    "section": "Helmert contrast",
    "text": "Helmert contrast\nCompares from the second to the last phase with the mean of all preceding phases.\nThe Intercept is the overall mean.\nThe predictors are the mean differences from a phase mean to the mean of all preceding phases.\n\nhelmert &lt;- contr.helmert(4)\ncolnames(helmert) &lt;- c(\"B1vsA1\", \"A2vsA1_B1\", \"B2vsA1_B1_A2\")\nhelmert\n\n  B1vsA1 A2vsA1_B1 B2vsA1_B1_A2\n1     -1        -1           -1\n2      1        -1           -1\n3      0         2           -1\n4      0         0            3\n\nlm(values~phase, data=df, contrasts = list(phase = helmert)) |&gt; coef()\n\n      (Intercept)       phaseB1vsA1    phaseA2vsA1_B1 phaseB2vsA1_B1_A2 \n           20.325             6.100            -1.700             2.225 \n\nc(Intercept = grand_mean,\n  phaseB1vsA1 = (25.9 + -13.7) / 2, \n  phaseA2vsA1_B1 = (14.7  + (-13.7-25.9)/2) / 3,\n  phaseB2vsA1_B1_A2 = (27 + (-13.7-25.9-14.7)/3) /4)\n\n        Intercept       phaseB1vsA1    phaseA2vsA1_B1 phaseB2vsA1_B1_A2 \n           20.325             6.100            -1.700             2.225"
  },
  {
    "objectID": "posts/contrasts/index.html#revert-helmert",
    "href": "posts/contrasts/index.html#revert-helmert",
    "title": "Contrasts in single-cases",
    "section": "Revert Helmert",
    "text": "Revert Helmert\nComparing the second to last phase against the mean of all preceding phases\nThe Intercept is the grand mean.\nThe predictors are the differences from a phase to the mean of the preeding phases.\nCompare phase2 vs.¬†phase 1, phase 3 vs.¬†mean of phase 1 and 2, phase4 vs.¬†mean of phases 1,2,3 (Intercept is overall mean)\n\nrevers_helmert &lt;- matrix(c(-1/2, 1/2, 0, 0, -1/3, -1/3, 2/3, 0, -1/4, -1/4, -1/4, 3/4), ncol = 3)\ncolnames(revers_helmert) &lt;- c(\"B1vsA1\", \"A2vsA1_B1\", \"B2vsA1_B1_A2\")\nrevers_helmert\n\n     B1vsA1  A2vsA1_B1 B2vsA1_B1_A2\n[1,]   -0.5 -0.3333333        -0.25\n[2,]    0.5 -0.3333333        -0.25\n[3,]    0.0  0.6666667        -0.25\n[4,]    0.0  0.0000000         0.75\n\nlm(values~phase, data=df, contrasts = list(phase = revers_helmert)) |&gt; coef()\n\n      (Intercept)       phaseB1vsA1    phaseA2vsA1_B1 phaseB2vsA1_B1_A2 \n           20.325            12.200            -5.100             8.900 \n\nc(Intercept = grand_mean,\n  phaseB1vsA1 = 25.7 - 13.7,\n  phaseA2vsA1_B1 = 14.7 - (13.7+25.9)/2,\n  phaseB2vsA1_B1_A2 = 27 - (13.7+25.9+14.7)/3)\n\n        Intercept       phaseB1vsA1    phaseA2vsA1_B1 phaseB2vsA1_B1_A2 \n           20.325            12.000            -5.100             8.900"
  },
  {
    "objectID": "posts/contrasts/index.html#cummulative",
    "href": "posts/contrasts/index.html#cummulative",
    "title": "Contrasts in single-cases",
    "section": "Cummulative",
    "text": "Cummulative\nCompare mean of second to last phase to mean of preceding phase\nThe Intercept is the mean of the first phase.\nThe predictors are the differences from a phase to the preeding phase.\n\ncumulative &lt;- matrix(c(0,1,1,1, 0,0,1,1, 0,0,0,1), ncol = 3)\ncolnames(cumulative) &lt;- c(\"B1vsA1\",\"A2vsB1\",\"B2vsA2\")\ncumulative\n\n     B1vsA1 A2vsB1 B2vsA2\n[1,]      0      0      0\n[2,]      1      0      0\n[3,]      1      1      0\n[4,]      1      1      1\n\nlm(values~phase, data=df, contrasts = list(phase = cumulative)) |&gt; coef()\n\n(Intercept) phaseB1vsA1 phaseA2vsB1 phaseB2vsA2 \n       13.7        12.2       -11.2        12.3 \n\nc(Intercept = 13.7,\n  phaseB1vsA1 = 25.9 - 13.7, \n  phaseA2vsB1 = 14.7 - 25.9,\n  phaseB2vsA2 = 27 - 14.7)\n\n  Intercept phaseB1vsA1 phaseA2vsB1 phaseB2vsA2 \n       13.7        12.2       -11.2        12.3"
  },
  {
    "objectID": "course_R_intro.html",
    "href": "course_R_intro.html",
    "title": "Courses: Introduction to data analysis with R",
    "section": "",
    "text": "Courses: Introduction to data analysis with R\n\n\nSession 1: Introduction\n\n\nSlides: Introduction\n\n\nSession 1b: RStudio\n\n\n\n\nSession 2: Basics: Datatypes\n\n\nSlides: Basics\n\n\nSession 3: Sophisticated subsetting\n\n\nSlides: Sophisticated subsetting\n\n\nSession 4: Libraries, projects, and importing data\n\n\nSlides: Libraries, projects, and importing data\nExample file: cars.xlsx\n\n\nSession 5: Rmarkdown\n\n\nSlides: Rmarkdown\n\n\nSession 6: tidyverse\n\n\nSlides: Rmarkdown\n\n\nSession 7: Data preparation with dplyr\n\n\nSlides: dplyr\n\n\nSession 8: Graphics with gpplot2\n\n\nSlides: ggplot2"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Active projects\n\nESPENQLB-DISISDYNAMIKSiKLedUEREP Uganda\n\n\n\n\n\n\n\n\n\nTitle\nEmotional, social, and psychological development in inclusive primary schools\n\n\n\nOriginal: Emotionale, soziale und psychische Entwicklung an der inklusiven Grundschule\n\n\nTeam\nThomas Hennemann; J√ºrgen Wilbert\nJohanna Krull; Karolina Urton; Jannis Bosch; Ella Baer\n\n\nHomepage\nNot available\n\n\nTerm\n1.9.2021 - 31.8.2024\n\n\nFunding\nSchool district Mettmann, Germany\n\n\n\n\n\n\n\n\nTitle\nDiagnostic of internalizing psychological problems in schools\n\n\n\nOriginal: Diagnostik internalisierender St√∂rungen an der inklusiven Schule\n\n\nTeam\nJ√ºrgen Wilbert; Jannnis Bosch; Ella Baer\n\n\nHomepage\nProject homepage\n\n\nTerm\n1.2.2021 - 30.12.2023\n\n\nFunding\nFederal Ministry of Education and Research - BMBF\n\n\n\n\n\n\n\n\nTitle\nDynamic testing as a perspective for intervention oriented diagnostic decisions\n\n\n\nOriginal: Dynamisches Testen als Perspektive fuÃàr f√∂rderdiagnostische Entscheidungen in der Schule\n\n\nTeam\nMoritz B√∂rnert-Ringleb; Claudia M√§hler; J√ºrgen Wilbert; Julia K√ºttner; Linda Kuhr\n\n\nHomepage\nhttp:://www.dynamik-projekt.de\n\n\nTerm\n1.11.2021 - 31.10.2024\n\n\nFunding\nFederal Ministry of Education and Research - BMBF\n\n\n\n\n\n\n\n\nTitle\nProcess monitoring and support of language education in inclusive classes\n\n\n\nOriginal: Sprachbildungsprozesse in inklusiven Klassen im Lernverlauf diagnostizieren und unterstuÃàtzen\n\n\nTeam\nMarkus Linnemann; Gabriele Kniffka; Petra Gretsch; J√ºrgen Wilbert\n\n\nHomepage\nNot available\n\n\nTerm\n1.11.2021 - 31.10.2024\n\n\nFunding\nFederal Ministry of Education and Research - BMBF\n\n\n\n\n\n\n\n\n\n\n\n\nTitle\nEducational Research on Educational Participation in Uganda\n\n\nTeam\nMichel Knigge; Wolfgang Lauterbach; J√ºrgen Wilbert\n\n\nHomepage\nNot available\n\n\nTerm\nsince 2019\n\n\n\n\n\n\n\n\n\nCompleted projects\n\nKOMPASSMettmann 20QLB-PSI DiagnostikMettmann\n\n\n\n\n\nTitle\nCooperative behavior modification and computer-based-training for students with behavioral and academic problems\n\n\n\nOriginal: Kooperative Verhaltensmodifikation und PC-basierte F√∂rderung bei Verhaltensauff√§lligkeiten und Schulschwierigkeiten\n\n\nTeam\nMichael von Aster; Christian Huber; Gerd Schulte-K√∂rne; J√ºrgen Wilbert\nLinda Kuhr; Moritz B√∂rnert (see homepage for full list)\n\n\nHomepage\nProject homepage\n\n\nTerm\n1.10.2018 - 30.9.2021\n\n\nFunding\nFederal Ministry of Education and Research - BMBF\n\n\n\n\n\n\n\n\nTitle\nSchool on its way to inclusion\n\n\n\nOriginal: Mettmann 20: Schule auf dem Weg zur Inklusion\n\n\nTeam\nThomas Hennemann; J√ºrgen Wilbert\nJohanna Krull; Karolina Urton (see homepage for full list)\n\n\nHomepage\nProject homepage\n\n\nTerm\n1.11.2016 - 31.10.2020\n\n\nFunding\nSchool district Mettmann, Germany\n\n\n\n\n\n\n\n\nTitle\nDiagnostic competences of teachers in inclusive classes\n\n\n\nOriginal: Diagnostische Kompetenz von Lehrkr√§ften im inklusiven Unterricht\n\n\nTeam\nJ√ºrgen Wilbert; Jana Grubert; Lynn Scherreiks\n\n\nHomepage\nProject homepage\n\n\nTerm\n1.9.2015 - 31.8.2019\n\n\nFunding\nFederal Ministry of Education and Research - BMBF\n\n\n\n\n\n\n\n\n\n\n\n\nTitle\nInclusive school development\n\n\n\nOriginal: Wissenschaftliche Begleitung zur inklusiven Schulentwicklung im Kreis Mettmann\n\n\nTeam\nThomas Hennemann; Clemens Hillenbrand\nJohanna Krull; Karlina Urton; J√ºrgen Wilbert\n\n\nTerm\n1.8.2012 - 30.7.2015\n\n\nFunding\nSchool district Mettmann, Germany"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Homepage J√ºrgen Wilbert",
    "section": "",
    "text": "Hello!\n\nThis is the centre of all my web activities, a place where anyone interested in my work can start.\nMy name is J√ºrgen Wilbert. I am a Professor of Research Methods and Diagnostics at the Department of Inclusive Education at the University of Potsdam in Germany. I studied education at the University of Cologne, where I also did my doctorate in cognitive psychology. I then obtained a permanent position as a senior researcher at the Department of Special Education. I later habilitated at the Carl-von-Osietzky University of Oldenburg on the topic of ‚ÄúPedagogy and Psychology in Learning Disabilities‚Äù.\nMy work focuses on:\n\nSingle-case research designs, analysis of single-case data, and reporting of single-case based results.\nSocial inclusion and social participation the classroom.\nImplementation of Open Science and Data Science concepts in special education research."
  },
  {
    "objectID": "students.html",
    "href": "students.html",
    "title": "Graduate Students",
    "section": "",
    "text": "Completed PhD students\n\n\n\n\n\n\n\n\nName\nField\nGraduation\n\n\n\n\nProf.¬†Dr.¬†Karolina Urton\nInclusive school development\n2016\n\n\nDr.¬†Johanna Krull\nSocial Inclusion\n2018\n\n\nProf.¬†Dr.¬†Moritz B√∂rnert-Ringleb\nDynamic Testing\n2018\n\n\nDr.¬†Pawel Kulawiak\nSociometric data analyzes\n2020\n\n\nDr.¬†Jannis Bosch\nSocial comparison and interest development\n2020\n\n\n\n\n\nPresent PhD students\n\n\n\n\n\n\n\n\nName\nField\nStarted\n\n\n\n\nAnja Schwalbe\nSocial norms in inclusive classrooms\n2014\n\n\nLinda Kuhr\nMath anxiety\n2018\n\n\nElla Baer\nDiagnosing students‚Äô internalization problems in the classroom\n2020\n\n\nAnte Pavic\n\n2022\n\n\nLydia K√ºttner\n\n2022"
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Publications",
    "section": "",
    "text": "Updated 2023-06-12\n\nJournal papers\n\nUrton, K., Wilbert, J., Krull, J., & Hennemann, T. (accepted). Factors Explaining Teachers‚Äô Intention to Implement Inclusive Practices in the Classroom: Indications Based on the Theory of Planned Behaviour. Teaching and Teacher Education.\nBosch, J., & Wilbert, J. (2023). The Impact of Social Comparison Processes on Self-Evaluation of Performance, Self-Concept, and Task Interest. Frontiers in Education: Educational Psychology.\nKrull, J., Urton, K., Kulawiak, P. R., Wilbert, J., & Hennemann, T. (2022). Social-relational classroom climate and its link to primary students‚Äô behavioral problems. Empirische Sonderp√§dagogik, 24(2), 22.\nLeidig, T., Casale, G., Wilbert, J., Hennemann, T., Volpe, R. J., Briesch, A., & Grosche, M. (2022). Individual, generalized, and moderated effects of the good behavior game on at-risk primary school students: A multilevel multiple baseline study using behavioral progress monitoring. Frontiers in Education, 7. https://doi.org/10.3389/feduc.2022.917138\nWilbert, J., L√ºke, T., & B√∂rnert-Ringleb, M. (2022). Statistical Power of Piecewise Regression Analyses of Single-Case Experimental Studies Addressing Behavior Problems. Frontiers in Education Educational Psychology, 7. https://doi.org/10.3389/feduc.2022.917944\nSchmidt, H., Felisatti, A., von Aster, M., Wilbert, J., von Moers, A., & Fischer, M. H. (2021). Neuromuscular Diseases Affect Number Representation and Processing: An Exploratory Study. Frontiers in Psychology, 12, 3710. https://doi.org/10.3389/fpsyg.2021.697881\nSchwalbe, A., M√ºller, C. M., & Wilbert, J. (2021). Wahrgenommene Gruppennormen und ihre Bedeutung f√ºr die soziale Akzeptanz und Ablehnung in Grundschulklassen. Zeitschrift f√ºr Grundschulforschung. https://doi.org/10.1007/s42278-021-00107-w\nWilbert, J., Bosch, J., & L√ºke, T. (2021). Validity and judgement bias in visual analysis of single-case data. International Journal for Research in Learning Disabilities, 5(1), 13‚Äì24. https://doi.org/10.28987/ijrld.5.1.13\nB√∂rnert-Ringleb, M., & Wilbert, J. (2020). Die Vorhersage von Mathe- und Leseleistungen durch dynamisches Testen. Lernen und Lernst√∂rungen, 1‚Äì12. https://doi.org/10.1024/2235-0977/a000331\nKulawiak, Pawel R., Wilbert, J., Schlack, R., & B√∂rnert-Ringleb, M. (2020). Prediction of child and adolescent outcomes with broadband and narrowband dimensions of internalizing and externalizing behavior using the child and adolescent version of the Strengths and Difficulties Questionnaire. PLOS ONE, 15(10), e0240312. https://doi.org/10.1371/journal.pone.0240312\nD√ºnkel, N., Knigge, M., & Wilbert, J. (2020). Determinanten und Akkuratheit von Sch√ºlerurteilen √ºber sprachliche F√§higkeiten von Mitsch√ºler(inne)n im Deutschen und den Herkunftssprachen T√ºrkisch und Russisch. Zeitschrift f√ºr Erziehungswissenschaft. https://doi.org/10.1007/s11618-020-00972-8\nHoffmann, L., Wilbert, J., Lehofer, M., & Schwab, S. (2020). Are we good friends? ‚Äì Friendship preferences and the quantity and quality of mutual friendships. European Journal of Special Needs Education, 36(4), 502‚Äì5016. https://doi.org/10.1080/08856257.2020.1769980\nBosch, J., & Wilbert, J. (2020). Contrast and Assimilation Effects on Self-Evaluation of Performance and Task Interest in a Sample of Elementary School Children. Frontiers in Education, 4. https://doi.org/10.3389/feduc.2019.00165\nKulawiak, P. R., Urton, K., Krull, J., Hennemann, T., & Wilbert, J. (2020). Internalizing Behaviour of Sociometrically Neglected Students in Inclusive Primary Classrooms - A Methodological Issue? Frontiers in Education, 5. https://doi.org/10.3389/feduc.2020.00032\nWilbert, J., Urton, K., Krull, J., Kulawiak, P. R., Schwalbe, A., & Hennemann, T. (2020). Teachers‚Äô Accuracy in Estimating Social Inclusion of Students With and Without Special Educational Needs. Frontiers in Education, 5. https://doi.org/10.3389/feduc.2020.598330\nB√∂rnert-Ringleb, M., & Wilbert, J. (2019). Beitrag eines dynamischen gegen√ºber einem statischen kognitiven Test zur Vorhersage der Schulleistung. Empirische Sonderp√§dagogik, 11(3), 175‚Äì190. https://doi.org/10.25656/01:17778\nKulawiak, Pawel R., & Wilbert, J. (2019). Introduction of a new method for representing the sociometric status within the peer group: the example of sociometrically neglected children. International Journal of Research & Method in Education, 1‚Äì19. https://doi.org/10.1080/1743727X.2019.1621830\nB√∂rnert-Ringleb, M., & Wilbert, J. (2018). The Association of Strategy Use and Concrete-Operational Thinking in Primary School. Frontiers in Education, 3. https://doi.org/10.3389/feduc.2018.00038\nKrull, J., Wilbert, J., & Hennemann, T. (2018). Does social exclusion by classmates lead to behaviour problems and learning difficulties or vice versa? A cross-lagged panel analysis. European Journal of Special Needs Education, 33(2), 235‚Äì253. https://doi.org/10.1080/08856257.2018.1424780\nHennemann, T., Hillenbrand, C., Fitting-Dahlmann, K., Wilbert, J., & Urton, K. (2018). Auf dem Weg zum inklusiven Schulsystem im Kreis Mettmann ‚Äì Konzeption der wissenschaftlichen Begleitevaluation. Zeitschrift f√ºr Heilp√§dagogik, 69(1), 4‚Äì16.\nKrull, J., Urton, K., Wilbert, J., & Hennemann, T. (2018). Der Kreis Mettmann auf dem Weg zum inklusiven Schulsystem ‚Äì zentrale Ergebnisse der wissenschaftlichen Begleitung. Zeitschrift f√ºr Heilp√§dagogik, 69(1), 17‚Äì39.\nUrton, K., B√∂rnert-Ringleb, M., Krull, J., Wilbert, J., & Hennemann, T. (2018). Inklusives Schulklima: Konzeptionelle Darstellung eines Rahmendmodells. Zeitschrift f√ºr Heilp√§dagogik, 69, 40‚Äì52.\nBosch, J., & Wilbert, J. (2017). Contrast and Assimilation Effects on Task Interest in an Academic Learning Task. Frontline Learning Research, 5(2), 60‚Äì78. https://doi.org/10.14786/flr.v5i2.292\nGr√ºnke, M., Wilbert, J., Tsiriotakis, I. K., & Agirregoikoa, A. L. (2017). Improving the Length and Quality of Texts Written by Fourth Graders With Learning Disabilities Through a Peer-Tutoring Graphic Organizing Strategy. Insights into Learning Disabilities, 14(2), 167‚Äì188. https://eric.ed.gov/?q=Improving+the+Length+and+Quality+of+Texts+Written+by+Fourth+Graders+With+Learning+Disabilities+Through+a+Peer-Tutoring+Graphic+Organizing+Strategy.+Insights+into+Learning+Disabilities&id=EJ1164946\nHennemann, T., Casale, G., Wilbert, J., Grosche, M., Fitting-Dahlmann, K., H√∂vel, D., Hagen, T., Leidig, T., & Melzer, C. (2017). ‚ÄûSchulen auf dem Weg zur Inklusion‚Äù Konzeption, Evaluation und erste Befunde eines landesweiten Qualifizierungsprogrammes zur Umsetzung von Inklusion in Nordrhein-Westfalen. Zeitschrift f√ºr Heilp√§dagogik.\nWilbert, J., Urton, K., & Grubert, J. (2016). Entwicklung eines Verfahrens zur Messung des inklusionsspezifischen Selbstwirksamkeitserlebens im schulischen Kontext. Empirische Sonderp√§dagogik, 8(3), 289‚Äì302. https://doi.org/10.25656/01:12607\nUrton, K., Wilbert, J., Grosche, M., & Hennemann, T. (2016). Vergleich der beruflichen Interessenstruktur von Studierenden der Sonderp√§dagogik mit den Anforderungen des sonderp√§dagogischen Lehrerberufs. Zeitschrift f√ºr Bildungsforschung. https://doi.org/10.1007/s35834-016-0160-5\nB√∂rnert, M., & Wilbert, J. (2016). Dynamisches Testen als neue Perspektive in der sonderp√§dagogischen Diagnostik - Theorie, Evidenzen, Impulse f√ºr Forschung und Praxis. Zeitschrift f√ºr Heilp√§dagogik, 67(4), 156‚Äì167.\nHintz, A.-M., Urton, K., Krull, J., Wilbert, J., & Hennemann, T. (2015). Teachers‚Äô Perceptions of Opportunities and Threats Concerning Inclusive Schooling in Germany at an Early Stage of Inclusion: Analyses of a Mixed Methodology Approach. Journal of Cognitive Education and Psychology, 14(3), 357‚Äì374. https://doi.org/10.1891/1945-8959.14.3.357\nUrton, K., Wilbert, J., & Hennemann, T. (2015). Die Einstellung zur Integration und die Selbstwirksamkeit von Lehrkr√§ften. Psychologie in Erziehung und Unterricht, 62(2), 147‚Äì157. https://doi.org/10.2378/peu2015.art09d\nB√∂rnert, M., & Wilbert, J. (2015). Thinking-aloud protocols of Piagetian tasks: Insights into problem-solving processes of primary school students. Insights on Learning Disabilities, 12(1), 19‚Äì34.\nGr√ºnke, M., B√ºy√ºknarci, √ñ., Wilbert, J., & Breuer, Esther. (2015). To what extent do certain characteristics of a child‚Äôs written story influence the way it is rated? Insights into features necessary for supporting struggling writers. Insights into Learning Disabilities, 12(2), 163‚Äì177.\nKulawiak, Pawel R., & Wilbert, J. (2015). Methoden zur Analyse der sozialen Integration von Schulkindern mit sonderp√§dagogischem F√∂rderbedarf im gemeinsamen Unterricht. Empirische Sonderp√§dagogik, 7(3), 241‚Äì257.https://doi.org/10.25656/01:11385\nRietz, C., & Wilbert, J. (Hrsg.). (2015). Schwerpunktthema: Best-Practice der Datenanalyse in sonderp√§dagogischen Forschungsfeldern. Empirische Sonderp√§dagogik, 7(3).\nKrull, J., Wilbert, J., & Hennemann, T. (2014a). Soziale Ausgrenzung von Erstkl√§sslerinnen und Erstkl√§sslern mit sonderp√§dagogischem F√∂rderbedarf im Gemeinsamen Unterricht. Empirische Sonderp√§dagogik, 6(1), 59‚Äì75.\nKrull, J., Wilbert, J., & Hennemann, T. (2014b). The Social and Emotional Situation of First Graders with Classroom Behavior Problems and Classroom Learning Difficulties in Inclusive Classes. Learning Disabilities: A Contemporary Journal, 12(2), 169‚Äì190.\nL√ºke, T., Wilbert, J., Weichselbaum, M., & Gr√ºnke, M. (2014). Zur Sichtbarkeit der Fachzeitschrift ‚ÄûEmpirische Sonderp√§dagogik‚Äù ‚Äì Eine bibliometrische Analyse. Empirische Sonderp√§dagogik, 6(4), 363‚Äì370.\nUrton, K., Wilbert, J., & Hennemann, T. (2014a). Attitudes towards inclusion and self-efficacy of principals and teachers in German primary schools. Learning Disabilities: A Contemporary Journal, 12(2), 151‚Äì168.\nUrton, K., Wilbert, J., & Hennemann, T. (2014b). Der Zusammenhang zwischen der Einstellung zur Integration und der Selbstwirksamkeit von Schulleitungen und deren Kollegien. Empirische Sonderp√§dagogik, 6(1), 3‚Äì16.\nGr√ºnke, M., Wilbert, J., & Stegemann-Calder, K. (2013). Analyzing the effects of story mapping on the reading comprehension of children with low intellectual abilities. Learning Disabilities: A Contemporary Journal, 11(2), 51‚Äì64.\nHuber, C., & Wilbert, J. (2012). Soziale Ausgrenzung von Sch√ºlern mit sonderp√§dagogischem F√∂rderbedarf und niedrigen Schulleistungen im gemeinsamen Unterricht. Empirische Sonderp√§dagogik, 4(2), 147‚Äì165.\nWilbert, J., & Grosche, M. (2012). A dissociation of implicit and explicit spatial sequence learning in a group of students with learning difficulties. Journal of Cognitive Education and Psychology, 11(3), 301‚Äì316.\nWilbert, J., & Haider, H. (2012). The subjective experience of committed errors and the Discrepancy-Attribution hypothesis. Acta Psychologica, 139, 370‚Äì381. https://doi.org/10.1016/j.actpsy.2011.11.010\nWilbert, J. (2011). Die Einsetzbarkeit der Skalen zur Erfassung der Lern- und Leistungsmotivation (SELLMO) bei Sch√ºlern des F√∂rderschwerpunkts Lernen. Zeitschrift f√ºr Heilp√§dagogik, 62, 11‚Äì17.\nWilbert, J., & Linnemann, M. (2011). Kriterien zur Analyse eines Tests zur Lernverlaufsdiagnostik. Empirische Sonderp√§dagogik, 3(3), 225‚Äì242.\nHennemann, T., Hillenbrand, C., Wilbert, J., Franke, S., Spie√ü, R., J√ºrgens, J., & G√∂rgens, G. (2010). Kompetenzen und Risiken in der Transition in die Hauptschule - eine Querschnittsuntersuchung von Sch√ºlerinnen und Sch√ºlern der 5. Jahrgangsstufen. Empirische Sonderp√§dagogik, 2(4), 36‚Äì49.\nNeugebauer, U., & Wilbert, J. (2010). Zum Zusammenhang zwischen Bew√§ltigungsstil und Burnout-Symptomen bei Lehrkr√§ften der F√∂rderschule Lernen. Empirische Sonderp√§dagogik, 2(3), 69‚Äì82.\nWilbert, J. (2010). Stereotype-Threat Effekte bei Sch√ºlern des F√∂rderschwerpunkts Lernen. Heilp√§dagogische Forschung, 36(4), 154‚Äì161.\nWilbert, J., Grosche, M., & Gerdes, H. (2010). Effects of Evaluative Feedback on Rate of Learning and Task Motivation: An Analogue Experiment. Learning Disabilities: A Contemporary Journal, 8(1), 43‚Äì52.\nWilbert, J., & Gr√ºnke, M. (2010a). Ein Vergleich des Lehrerbildes von Sch√ºlern der F√∂rderschule Lernen und der Regelschule. Heilp√§dagogische Forschung, 36(1), 2‚Äì14.\nWilbert, J., & Gr√ºnke, M. (2010b). Norms and goals of appraisal of German teachers for students with learning disabilities. Learning Disabilities: A Contemporary Journal, 8(2), 19‚Äì30.\nWilbert, J., & Gerdes, H. (2009). Die Bezugsnormwahl bei der Bewertung schulischer Leistungen durch angehende Lehrkr√§fte des F√∂rderschwerpunktes Lernen. Heilp√§dagogische Forschung, 35, 122‚Äì135.\nWilbert, J., & Gerdes, H. (2007). Lehrerbild von Sch√ºlern und Lehrern: Eine empirische Studie zum Vergleich der Vorstellungen vom idealen und vom typischen Lehrer. Psychologie in Erziehung und Unterricht, 54(3), 208‚Äì222.\n\n\n\nBook chapters\n\nWilbert, J., & L√ºke, T. (2023). Leistungsbewertung und Leistungsattribution. In M. B√∂rnert-Ringleb, G. Casale, M. Balt, & M. Herzog (Eds.), Lern- und Verhaltensschwierigkeiten in der Schule‚ÄîErscheinungsformen, Erkl√§rungsmodelle und Implikationen f√ºr die Praxis (pp.¬†167‚Äì176). Kohlhammer.\nGabriel, T., B√∂rnert‚ÄêRingleb, M. & Wilbert, J. (2022). Dynamisches Testen im Spannungsfeld von Selektion und Modifikation. In M. Gebhardt, D. Scheer & M. Schurig (Hrsg.), Handbuch der sonderp√§dagogischen Diagnostik. Grundlagen und Konzepte der Statusdiagnostik, Prozessdiagnostik und F√∂rderplanung (p.¬†313‚Äê322). Regensburg: Universit√§tsbibliothek. https://doi.org/10.5283/epub.53149\nScherreiks, L., Kuhr, L., & Wilbert, J. (2022). Ver√§nderung der selbsteingesch√§tzten Kompetenz zur Diagnostik psychischer Auff√§lligkeiten im Psychodiagnostischen Praktikum. In J. Jennek (Ed.), Professionalisierung in Praxisphasen: Ergebnisse der Lehrerbildungsforschung an der Universit√§t Potsdam (p.¬†23). Universit√§tsverlag Potsdam. DOI: 10.25932/publishup-50096\nWilbert, J., & B√∂rnert, M. (2022). Unterricht. In I. Hedderich, G. Biewer, J. Hollenweger, & R. Markowetz (Hrsg.), Handbuch Inklusion und Sonderp√§dagogik (S. 346‚Äì353). 2. Auflage. Julius Klinkhardt.\nB√∂rnert-Ringleb, M., & Wilbert, J. (2022). Verlaufsdiagnostik und einzelfallbasierte Ver√§nderungsmessung im Rahmen schulischer F√∂rderung. In Y. Blumenthal, S. Blumenthal, & K. Mahlau (Eds.), Kinder mit Lern- und emotional-sozialen Entwicklungsauff√§lligkeiten in der Schule (pp.¬†72‚Äì77). Kohlhammer.\nWilbert, J., & Krull, J. (2021). Die Bedeutung von Peers f√ºr die soziale Partizipation von Lernenden mit Lern- und Verhaltensproblemen in inklusiven Schulklassen. In M. Kreutzmann, L. Zander, & B. Hannover (Hrsg.), Aufwachsen mit Anderen. Peerbeziehungen als Bildungsfaktor (S. 134‚Äì152). Kohlhammer.\nB√∂rnert-Ringleb, M., & Wilbert, J. (2021). Dynamisches Testen: Diagnostik als M√∂glichkeit der Modellierung von Kompetenzentwicklung. In C. M√§hler & M. Hasselhorn (Hrsg.), Inklusionsherausforderungen. Hogrefe.\nScherreiks, L., Kuhr, L., & Wilbert, J. (2021). Ver√§nderung der selbsteingesch√§tzten Kompetenz zur Diagnostik psychischer Auff√§lligkeiten im Psychodiagnostischen Praktikum.\nUrton, K., Wilbert, J., & Knigge, M. (2019). Die Entwicklung der Selbstwirksamkeit und des Rollenverst√§ndnisses w√§hrend des Praxissemesters von Studierenden des Lehramtes f√ºr Sonderp√§dagogische F√∂rderung. In D. Zimmermann, U. Fickler-Stang, L. Dietrich, & K. Weiland (Hrsg.), Professionalisierung f√ºr Unterricht und Beziehungsarbeit mit psychosozial beeintr√§chtigten Kindern und Jugendlichen (S. 145‚Äì157). Klinkhammer.\nUrton, K., B√∂rnert-Ringleb, M., & Wilbert, J. (2018). Gestaltung eines inklusiven Schulklimas als Schulentwicklungsaufgabe. In F. Hellmich, G. G√∂rel, & M. L√∂per (Hrsg.), Inklusive Schul- und Unterrichtsentwicklung. Kohlhammer.\nB√∂rnert-Ringleb, M., Bosch, J., & Wilbert, J. (2018). Lernverlaufsdiagnostik. In M. Dziak-Mahler, T. Hennemann, S. Jaster, T. Leidig, & J. Springob (Hrsg.), Fachdidaktik inklusiv II - (Fach-)Unterricht inklusiv gestalten - Theoretische Ann√§herungen und praktische Umsetzungen. Waxmann Verlag.\nGrubert, J., Kulawiak, P. R., Schwalbe, A., Scherreiks, L., B√∂rnert-Ringleb, M., & Wilbert, J. (2018). Fragebogen zur Erfassung diagnostischer Kompetenzen hinsichtlich psychischer Auff√§lligkeiten von Sch√ºler_innen. In Potsdamer Beitr√§ge zur Lehrerbildung und Bildungsforschung (S. 17‚Äì27). Universit√§t Potsdam.\nGrubert, J., Schwalbe, A., Kulawiak, P. R., & Wilbert, J. (2018). Seminarkonzept zur F√∂rderung inklusionsrelevanter Kompetenzen ‚Äì Diagnostik hinsichtlich psychischer Auff√§lligkeiten von Sch√ºler_innen. In Potsdamer Beitr√§ge zur Lehrerbildung und Bildungsforschung (S. 125‚Äì124). Universit√§t Potsdam.\nKulawiak, P. R., & Wilbert, J. (2018). Komplement√§re Studiendesigns zur Evidenzbasierung in der Bildungswissenschaft. In R. Haring & J. Siegm√ºller (Hrsg.), Evidenzbasierte Praxis in den Gesundheitsberufen (S. 17‚Äì31). Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-662-55377-0_2\nB√∂rnert, M., Grubert, J., & Wilbert, J. (2016). Lautes Denken als Methode zur Forschung und Diagnostik in inklusionsp√§dagogischen Handlungsfeldern (D. Gebele & A. L. Zepter, Hrsg.; S. 165‚Äì186). Gilles & Francke Verlag.\nBosch, J., Schaefer, A., Kulawiak, P. R., & Wilbert, J. (2016). Forschungsdesigns zur Untersuchung kausaler Beziehungen in den empirischen Bildungswissenschaften (D. Gebele & A. L. Zepter, Hrsg.; S. 138‚Äì164). Gilles & Francke Verlag.\nWilbert, J. (2015). Streuung, Standardabweichung und Varianz. In S. Ellinger & K. Koch (Hrsg.), Forschungsmethoden in der Heil- und Sonderp√§dagogik (S. 129‚Äì136). Hogrefe.\nWilbert, J., & Gr√ºnke, M. (2015). Kontrollierte Einzelfallforschung. In S. Ellinger & K. Koch (Hrsg.), Forschungsmethoden in der Heil- und Sonderp√§dagogik (S. 100‚Äì105). Hogrefe.\nWilbert, J., & B√∂rnert, M. (2015). Unterricht. In I. Hedderich, G. Biewer, J. Hollenweger, & R. Markowetz (Hrsg.), Handbuch Inklusion und Sonderp√§dagogik (S. 346‚Äì353). Julius Klinkhardt.\nLinnemann, M., & Wilbert, J. (2014). Do C-tests measure language comprehension of learning disabled students? In R. Grotjahn (Hrsg.), Der C-Test: Beitr√§ge aus der aktuellen Forschung/ The C-Test: Contributions from Current Research (S. 223‚Äì238). Lang.\nWilbert, J. (2014a). Instrumente zur Lernverlaufsmessung. G√ºtekriterien und Auswertungsherausforderungen. In M. Hasselhorn, W. Schneider, & U. Trautwein (Hrsg.), Lernverlaufsdiagnostik (S. 281‚Äì308). Hogrefe.\nWilbert, J. (2014b). Lern- und Leistungsmotivation. In A. Castello (Hrsg.), Entwicklungsrisiken bei Kindern und Jugendlichen: Pr√§vention im p√§dagogischen Alltag. Kohlhammer.\nWilbert, J. (2014c). Vermittlung von Basiskompetenzen zum Rechnen. In G. Lauth, M. Gr√ºnke, & J. Brunstein (Hrsg.), Interventionen bei Lernst√∂rungen: F√∂rderung, Training und Therapie in der Praxis (S. 209‚Äì219). Hogrefe.\nLinnemann, M., & Wilbert, J. (2010). The C-test: A valid instrument for screening language skills and reading comprehension of children with learning problems? In R. Grotjahn (Hrsg.), Der C-Test: Beitr√§ge aus der aktuellen Forschung/ The C-Test: Contributions from Current Research (S. 113‚Äì124). Lang.\nGr√ºnke, M., & Wilbert, J. (2008). Offener Unterricht und Projektunterricht. In M. Fingerle & S. Ellinger (Hrsg.), Sonderp√§dagogische F√∂rderung: F√∂rderkonzepte auf dem Pr√ºfstand (S. 13‚Äì33). Kohlhammer.\n\n\n\nBooks and reports\n\nKuhr, L., Napiany, S., Huber, C., & Wilbert, J. (2021). Abschlussbericht F1-Projekt KOMPASS Standorte: Potsdam/ Wuppertal (S. 317). University of Potsdam and University of Wuppertal.\nKrull, J., Urton, K., Hennemann, T., & Wilbert, J. (2021). Mettmann 2.0 ‚Äì Wissenschaftliche Begleitung auf dem Weg zum inklusiven Schulsystem des Kreises Mettmann Abschlussbericht (S. 68). University of Cologne.\nWilbert, J. (2022). Analyzing single-case data with R and scan. doi: 10.5281/zenodo.5713559. https://jazznbass.github.io/scan-Book/\nHennemann, T., Wilbert, J., & Hillenbrand, C. (2014). Wissenschaftliche Begleitung im Rahmen der Umsetzung zur inklusiven Schule im Kreis Mettmann (Mehrebenenanalyse 2010 ‚Äì 2012). Abschlussbericht. Universit√§t zu K√∂ln.\nBecker-Mrotzek, M., Ehlich, K., F√ºssenich, I., G√ºnther, H., Hasselhorn, M., Hopf, M., Jeuk, S., Lengyel, D., Neugebauer, U., Panagiotopoulou, A., Stanat, P., & Wilbert, J. (2013). Qualit√§tsmerkmale f√ºr Sprachstandsverfahren im Elementarbereich. Ein Bewertungsrahmen f√ºr fundierte Sprachdiagnostik in der Kita. Mercator-Institut f√ºr Sprachf√∂rderung und Deutsch als Zweitsprache.\nWilbert, J. (2011). Motivationale Faktoren in der Sonderp√§dagogik bei Lernst√∂rungen. (Habilitationsschrift). Universit√§t Oldenburg.\nWilbert, J. (2010). F√∂rderung der Motivation bei Lernst√∂rungen. Kohlhammer.\nWilbert, J. (2006). Die Etikettierung eines Verhaltens als Fehlerhaft: Eine empirische Untersuchung zur bewussten Gewahrwerdung eigener Verhaltensfehler. Pabst Science Publishers.\n\n\n\nSoftware\n\nWilbert, J. (2023). scplot: An R package for visualizing single-case data (0.3.0) [English]. University of Potsdam. https://CRAN.R-project.org/package=scplot\nWilbert, J., & L√ºke, T. (2023). Scan: Single-Case Data Analyses for Single and Multiple Baseline Designs. (0.57.1). University of Potsdam. https://CRAN.R-project.org/package=scan\nWilbert, J. (2020). scaledic: An R package for adding scaling information to variables in data frames (0.1.8). University of Potsdam. https://github.com/jazznbass/scaledic/\nWilbert, J., & L√ºke, T. (2019). Scan: Single-Case Data Analyses for Single and Multiple Baseline Designs. (0.40). University of Potsdam.\nWilbert, J. (2016). Scan: Single-Case Data Analyses for Single and Multiple Baseline Designs. (0.20). University of Potsdam."
  },
  {
    "objectID": "links.html",
    "href": "links.html",
    "title": "Links",
    "section": "",
    "text": "My homepage at the University of Potsdam\n\n\n\nResearch gate\n\n\n\nGithub\n\n\n\nEmpirische Sonderp√§dagogik (Journal Empirical Research in Special Education)\n\n\n\nORCID\n\n\n\nGoogle Scholar\n\n\n\nOFS - Open Science Framework\n\n\n\nMy personal Twitter account"
  },
  {
    "objectID": "rpackages.html",
    "href": "rpackages.html",
    "title": "R Packages",
    "section": "",
    "text": "scanscaledicscplotmcscanwmisc\n\n\n\nscan - Single-Case Data Analyses for Single and Multiple Baseline Designs\nThis package provides a collection of procedures for analyzing, visualizing, and managing single-case data. These include piecewise linear regression models, multilevel models, overlap indices (PND, PEM, PAND, PET, tauU, baseline corrected tau), and randomization tests. Data preparation functions support outlier detection, handling missing values, scaling, truncating, rank transformation, and smoothing. An exporting function helps to generate html and latex tables in a publication friendly style.\nMore details can be found at https://jazznbass.github.io/scan-Book/.\nState: Stable CRAN version and extended developmental version on github\ngithub: https://github.com/jazznbass/scan\nCRAN: https://CRAN.R-project.org/package=scan\nwebpage: https://jazznbass.github.io/scan/\n\n\n\n\nscaledic - A dictionary for scales\nscaledic is an R package for extending data frames and tibbles with several scale related attributes. It is designed to implement (psychometric) scale information to items of a data frame. These include values, labels, sub scales, weights etc.. A couple of functions help to organize, extract, replace and impute missing values, find typos, build scale scores etc.\nFor now, scaledic is already working and up to the task but still in an experimental stage where I might change the basic syntax.\nAlso documentation is poor. I am working on that.\nBasically, scaledic loads a dictionary file that contains all relevant information and applies these to a data frame. Here, every variable corresponding to the ones describes in the dictionary gets a new attribute dic which contains a list with all dictionary values for that variable.\nState: Working but still experimental\ngithub: https://github.com/jazznbass/scaledic\nwebpage: https://jazznbass.github.io/scaledic/\n\n\n\n\nscplot - Visualizing single-case data\nscplot is an extension to the scan package which provides powerful functions to generate single-case data plots. I try to keep the syntax simple and readable but nevertheless also allowing for sophisticated and complex depictions.\nThe generated plots are compatible to ggplot2.\nState: Stable CRAN version and extended developmental version on github\ngithub: https://github.com/jazznbass/scplot\nCRAN: https://CRAN.R-project.org/package=scplot\nwebpage: https://jazznbass.github.io/scplot/\n\n\n\n\nmcscan - Conduction Monte Carlo Single-Case Studies\nmcscan is another extension to the scan package which provides functions for designing, conducting, and visualizing the results of Monte-Carlo Single-Case studies.\nState: Experimental\ngithub: https://github.com/jazznbass/mcscan/\n\n\n\n\nwmisc - Wilbert‚Äôs miscellaneous functions\nThis R package comprises miscellaneous functions that I use to ease my work. It is developed to help people who work with my code.\nState: Experimental"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Private blog",
    "section": "",
    "text": "This blog is only for internal use (e.g.¬†teaching or sending ideas to colleagues). Please do not reference or cite things I say here :-)\n\n\n\n\n\n\n\n\n\n\n\n\nA link function for logistic regressions\n\n\n\nregression\n\n\nstatistics\n\n\nlink\n\n\nlogistic\n\n\n\nA brief explanation of the link function in logistic regression.\n\n\n\nJ√ºrgen Wilbert\n\n\nJun 22, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nTreatment vs.¬†effect contrasts\n\n\n\nregression\n\n\nstatistics\n\n\ncontrasts\n\n\n\nHere is a simple example to show the differences between treatment and effect contrasts.\n\n\n\nJ√ºrgen Wilbert\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nContrasts in single-cases\n\n\n\ncontrasts\n\n\nregression\n\n\nstatistics\n\n\n\nContrasts in regression modells\n\n\n\nJ√ºrgen Wilbert\n\n\nSep 27, 2022\n\n\n\n\n\n\n\n\n\n\n\n\neRm\n\n\n\nirt\n\n\nrasch\n\n\neRm\n\n\nstatistics\n\n\n\nAn overview of extended Rasch modelling in R with the eRm package.\n\n\n\nJ√ºrgen Wilbert\n\n\nMay 31, 2021\n\n\n\n\n\n\n\n\n\n\n\n\nCreate Rmarkdown webpage on gitHub\n\n\n\nRmarkdown\n\n\nGitHub\n\n\nRStudio\n\n\nWebpage\n\n\n\nShort description how to create an Rmarkdown webpage and publish it on gitHub\n\n\n\nJ√ºrgen Wilbert\n\n\nApr 19, 2021\n\n\n\n\n\n\n\n\n\n\n\n\nSetup a new github / Rstudio project\n\n\n\nGit\n\n\nGitHub\n\n\nRStudio\n\n\n\nSet up a git project in Rstudio and publish it to gitHub\n\n\n\nJ√ºrgen Wilbert\n\n\nMar 18, 2021\n\n\n\n\n\n\n\n\n\n\n\n\nMultivariate multilevel analyses\n\n\n\nStatistics\n\n\nR\n\n\nMultilevel\n\n\nBayesian\n\n\nnlme\n\n\nMCMCglmm\n\n\n\nA short description how to do Multivariate Multilevel Analyses in R with the nlme and MCMCglmm packages\n\n\n\nJ√ºrgen Wilbert\n\n\nMar 17, 2021\n\n\n\n\n\n\n\n\nNo matching items"
  }
]